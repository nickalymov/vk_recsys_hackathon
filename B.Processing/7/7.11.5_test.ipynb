{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a62bc246",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:29.484436Z",
     "iopub.status.busy": "2024-12-13T14:44:29.484069Z",
     "iopub.status.idle": "2024-12-13T14:44:29.491157Z",
     "shell.execute_reply": "2024-12-13T14:44:29.490474Z"
    },
    "papermill": {
     "duration": 0.013186,
     "end_time": "2024-12-13T14:44:29.492685",
     "exception": false,
     "start_time": "2024-12-13T14:44:29.479499",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T14:40:07.607960600Z",
     "start_time": "2024-12-18T14:40:07.586947100Z"
    }
   },
   "outputs": [],
   "source": [
    "number = '7.11.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df1c54f8",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:29.498999Z",
     "iopub.status.busy": "2024-12-13T14:44:29.498751Z",
     "iopub.status.idle": "2024-12-13T14:44:29.503332Z",
     "shell.execute_reply": "2024-12-13T14:44:29.502650Z"
    },
    "papermill": {
     "duration": 0.009478,
     "end_time": "2024-12-13T14:44:29.504930",
     "exception": false,
     "start_time": "2024-12-13T14:44:29.495452",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T14:40:08.399077400Z",
     "start_time": "2024-12-18T14:40:08.389141600Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/data/',\n",
    "    'val_pred_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/val/',\n",
    "    'test_pred_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/test/',\n",
    "    \n",
    "    'train_path' : 'train_interactions.parquet',\n",
    "    'test_path': 'test_pairs.csv',  \n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "    'folds_path' : 'fold.csv',\n",
    "    'val_output_path' : f'{number}_val',\n",
    "    'test_output_path' : f'{number}_test',\n",
    "    \n",
    "    'user_emb_size' : 256, \n",
    "    'item_emb_size' : 256, \n",
    "    'source_emb_size' : 256, \n",
    "    'age_emb_size' : 256, \n",
    "    'duration_emb_size' : 256, \n",
    "    'gender_emb_size' : 256, \n",
    "    \n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 16384,\n",
    "    'LR' : 0.001,\n",
    "    'EPOCHS' : 1,\n",
    "    'output_dim' : 3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc438ac",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:29.511959Z",
     "iopub.status.busy": "2024-12-13T14:44:29.511735Z",
     "iopub.status.idle": "2024-12-13T14:44:33.200738Z",
     "shell.execute_reply": "2024-12-13T14:44:33.200037Z"
    },
    "papermill": {
     "duration": 3.694446,
     "end_time": "2024-12-13T14:44:33.202987",
     "exception": false,
     "start_time": "2024-12-13T14:44:29.508541",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:18.793894800Z",
     "start_time": "2024-12-18T03:30:17.431260700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce4e9b6",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:33.209719Z",
     "iopub.status.busy": "2024-12-13T14:44:33.209381Z",
     "iopub.status.idle": "2024-12-13T14:44:33.279822Z",
     "shell.execute_reply": "2024-12-13T14:44:33.278975Z"
    },
    "papermill": {
     "duration": 0.075573,
     "end_time": "2024-12-13T14:44:33.281449",
     "exception": false,
     "start_time": "2024-12-13T14:44:33.205876",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:19.393700400Z",
     "start_time": "2024-12-18T03:30:18.795826700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device, torch decimal places and seed for reproducibility\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=40) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99a1acc",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:33.287711Z",
     "iopub.status.busy": "2024-12-13T14:44:33.287446Z",
     "iopub.status.idle": "2024-12-13T14:44:49.190871Z",
     "shell.execute_reply": "2024-12-13T14:44:49.189860Z"
    },
    "papermill": {
     "duration": 15.908885,
     "end_time": "2024-12-13T14:44:49.192975",
     "exception": false,
     "start_time": "2024-12-13T14:44:33.284090",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:24.108114300Z",
     "start_time": "2024-12-18T03:30:19.395649600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['target'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['like', 'dislike'], inplace=True)\n",
    "train['target'] = train['target'].astype('int8')\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "test = pd.read_csv(f\"{CONFIG['data_folder']}{CONFIG['test_path']}\")\n",
    "test_to_save = test.copy()\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['duration'] = items_meta['duration'] - 5\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "users_meta['prev_emb'] = [np.zeros(32, dtype=np.float32) for _ in range(len(users_meta))]\n",
    "users_meta['prev_emb_2'] = [np.zeros(32, dtype=np.float32) for _ in range(len(users_meta))]\n",
    "users_meta['prev_emb_3'] = [np.zeros(32, dtype=np.float32) for _ in range(len(users_meta))]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:24.278786400Z",
     "start_time": "2024-12-18T03:30:24.109107100Z"
    }
   },
   "id": "5c8742dd296203a9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "users_meta['prev_target'] = 0\n",
    "users_meta['prev_target_2'] = 0\n",
    "users_meta['prev_target_3'] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:24.293775100Z",
     "start_time": "2024-12-18T03:30:24.279845700Z"
    }
   },
   "id": "b5db66879f47df30",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de1c3e9",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:49.201252Z",
     "iopub.status.busy": "2024-12-13T14:44:49.200967Z",
     "iopub.status.idle": "2024-12-13T14:44:49.232298Z",
     "shell.execute_reply": "2024-12-13T14:44:49.231430Z"
    },
    "papermill": {
     "duration": 0.038447,
     "end_time": "2024-12-13T14:44:49.234499",
     "exception": false,
     "start_time": "2024-12-13T14:44:49.196052",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:24.328776300Z",
     "start_time": "2024-12-18T03:30:24.299852900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 num_ages=users_meta['age'].nunique(),\n",
    "                 num_durations=items_meta['duration'].nunique(),\n",
    "                 num_genders=users_meta['gender'].nunique(), \n",
    "                 output_dim=CONFIG['output_dim']): \n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "         \n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 128)\n",
    "        self.fc7 = nn.Linear(128, 64)\n",
    "        self.fc8 = nn.Linear(64, 32)\n",
    "        self.fc9 = nn.Linear(32, 32)\n",
    "        self.fc10 = nn.Linear(32, 16)\n",
    "        self.fc11 = nn.Linear(16, 8)\n",
    "        self.fc12 = nn.Linear(8, 8)\n",
    "        self.fc13 = nn.Linear(8 + 33 + 33 + 33, output_dim)\n",
    "        \n",
    "        self.gelu = nn.GELU()\n",
    "\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)  # Инициализация весов\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)  # Инициализация биасов нулями\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                init.xavier_uniform_(m.weight)  # Инициализация весов для Embedding\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids, embeddings, ids):\n",
    "\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "        age_emb = self.age_embedding(age_ids)\n",
    "        duration_emb = self.duration_embedding(duration_ids)\n",
    "        gender_emb = self.gender_embedding(gender_ids)\n",
    "        \n",
    "        x = torch.cat((user_emb, item_emb, source_emb, age_emb, duration_emb, gender_emb, embeddings), dim=1)\n",
    "        \n",
    "        x = self.gelu(self.fc1(x))\n",
    "        x = self.gelu(self.fc2(x))\n",
    "        x = self.gelu(self.fc3(x))\n",
    "        x = self.gelu(self.fc4(x))\n",
    "        x = self.gelu(self.fc5(x))\n",
    "        x = self.gelu(self.fc6(x))\n",
    "        x = self.gelu(self.fc7(x))\n",
    "        x = self.gelu(self.fc8(x))\n",
    "        x = self.gelu(self.fc9(x))\n",
    "        x = self.gelu(self.fc10(x))\n",
    "        x = self.gelu(self.fc11(x))\n",
    "        x = self.gelu(self.fc12(x))\n",
    "        x = torch.cat((x, ids), dim=1)\n",
    "        x = self.fc13(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17894aa0",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:49.243704Z",
     "iopub.status.busy": "2024-12-13T14:44:49.243308Z",
     "iopub.status.idle": "2024-12-13T14:44:49.248493Z",
     "shell.execute_reply": "2024-12-13T14:44:49.247551Z"
    },
    "papermill": {
     "duration": 0.012571,
     "end_time": "2024-12-13T14:44:49.250933",
     "exception": false,
     "start_time": "2024-12-13T14:44:49.238362",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:24.340818Z",
     "start_time": "2024-12-18T03:30:24.330833500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input dimension\n",
    "input_dim = (CONFIG['user_emb_size'] + \n",
    "             CONFIG['item_emb_size'] + \n",
    "             CONFIG['source_emb_size'] + \n",
    "             CONFIG['age_emb_size'] +\n",
    "             CONFIG['duration_emb_size'] + \n",
    "             CONFIG['gender_emb_size'] + \n",
    "             32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8cb91d",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:49.259820Z",
     "iopub.status.busy": "2024-12-13T14:44:49.259511Z",
     "iopub.status.idle": "2024-12-13T14:44:52.992713Z",
     "shell.execute_reply": "2024-12-13T14:44:52.991993Z"
    },
    "papermill": {
     "duration": 3.73904,
     "end_time": "2024-12-13T14:44:52.994728",
     "exception": false,
     "start_time": "2024-12-13T14:44:49.255688",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T03:30:26.573288100Z",
     "start_time": "2024-12-18T03:30:24.343775900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model, criterion and optimizer\n",
    "model = Model(input_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1217d008",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-13T14:44:53.001721Z",
     "iopub.status.busy": "2024-12-13T14:44:53.001383Z",
     "iopub.status.idle": "2024-12-13T14:59:46.638105Z",
     "shell.execute_reply": "2024-12-13T14:59:46.637032Z"
    },
    "papermill": {
     "duration": 893.642276,
     "end_time": "2024-12-13T14:59:46.639910",
     "exception": false,
     "start_time": "2024-12-13T14:44:52.997634",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-18T14:18:03.901689900Z",
     "start_time": "2024-12-18T03:30:26.584298300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 8891/8891 [10:46:35<00:00,  4.36s/batch, train_mean_loss=0.127721]  \n",
      "Epoch 1/1: 100%|██████████| 102/102 [01:00<00:00,  1.70batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/test/7.11.4_test_e0.csv\n",
      "Epoch [1/1]: Train Loss: 0.127721\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_num_samples = len(train)\n",
    "train_num_batches = (train_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "test_num_samples = len(test)\n",
    "test_num_batches = (test_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "##################################################################TRAIN##################################################################\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    with tqdm(range(train_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], train_num_samples)\n",
    "            \n",
    "            batch_main = train.iloc[start_idx:end_idx]\n",
    "            \n",
    "            batch_user_values = batch_main['user_id'].values\n",
    "            batch_item_values = batch_main['item_id'].values\n",
    "            \n",
    "            batch_users_meta = users_meta.loc[batch_user_values]\n",
    "            batch_items_meta = items_meta.loc[batch_item_values]\n",
    "            \n",
    "            targets = batch_main['target'].values\n",
    "            embeddings = np.stack(batch_items_meta['embeddings'].values)\n",
    "            \n",
    "            batch_embeddings = []\n",
    "            \n",
    "            for i in range(len(batch_user_values)):\n",
    "                user_id = batch_user_values[i]\n",
    "                target = targets[i] - 1\n",
    "\n",
    "                prev_emb = users_meta.at[user_id, 'prev_emb']  \n",
    "                prev_target = users_meta.at[user_id, 'prev_target']  \n",
    "                prev_emb_2 = users_meta.at[user_id, 'prev_emb_2']  \n",
    "                prev_target_2 = users_meta.at[user_id, 'prev_target_2']  \n",
    "                prev_emb_3 = users_meta.at[user_id, 'prev_emb_3']  \n",
    "                prev_target_3 = users_meta.at[user_id, 'prev_target_3']  \n",
    "                \n",
    "                users_meta.at[user_id, 'prev_emb_3'] = users_meta.at[user_id, 'prev_emb_2']\n",
    "                users_meta.at[user_id, 'prev_target_3'] = users_meta.at[user_id, 'prev_target_2']\n",
    "                users_meta.at[user_id, 'prev_emb_2'] = users_meta.at[user_id, 'prev_emb']\n",
    "                users_meta.at[user_id, 'prev_target_2'] = users_meta.at[user_id, 'prev_target']\n",
    "                users_meta.at[user_id, 'prev_emb'] = embeddings[i]\n",
    "                users_meta.at[user_id, 'prev_target'] = target\n",
    "                \n",
    "                concatenated_emb = np.concatenate([prev_emb, [prev_target], prev_emb_2, [prev_target_2], prev_emb_3, [prev_target_3]], axis=0)\n",
    "                batch_embeddings.append(concatenated_emb)\n",
    "            \n",
    "            targets = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "            embeddings = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "\n",
    "            batch_user_values = torch.tensor(batch_user_values, dtype=torch.long, device=device)\n",
    "            batch_item_values = torch.tensor(batch_item_values, dtype=torch.long, device=device)\n",
    "\n",
    "            batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "            batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "            batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "            batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "\n",
    "                        \n",
    "            batch_embeddings = torch.tensor(np.array(batch_embeddings), dtype=torch.float32, device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(batch_user_values, \n",
    "                            batch_item_values, \n",
    "                            batch_source_values, \n",
    "                            batch_age_values, \n",
    "                            batch_duration_values, \n",
    "                            batch_gender_values, \n",
    "                            embeddings,\n",
    "                            batch_embeddings)\n",
    "            \n",
    "            batch_loss = criterion(outputs, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += batch_loss.item()\n",
    "            t.set_postfix(train_mean_loss=f\"{train_running_loss / (batch_idx + 1):.6f}\")\n",
    "        \n",
    "##################################################################EVAL##################################################################\n",
    "    model.eval()\n",
    "    \n",
    "    outputs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(range(test_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as v:\n",
    "            for batch_idx in v:\n",
    "                start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "                end_idx = min(start_idx + CONFIG['BATCH_SIZE'], test_num_samples)\n",
    "                \n",
    "                batch_main = test.iloc[start_idx:end_idx]\n",
    "                \n",
    "                batch_user_values = batch_main['user_id'].values\n",
    "                batch_item_values = batch_main['item_id'].values\n",
    "    \n",
    "                batch_users_meta = users_meta.loc[batch_user_values]\n",
    "                batch_items_meta = items_meta.loc[batch_item_values]\n",
    "                \n",
    "                embeddings = np.stack(batch_items_meta['embeddings'].values)\n",
    "                \n",
    "                batch_embeddings = []\n",
    "                \n",
    "                for i in range(len(batch_user_values)):\n",
    "                    user_id = batch_user_values[i]\n",
    "    \n",
    "                    prev_emb = users_meta.at[user_id, 'prev_emb']  \n",
    "                    prev_target = users_meta.at[user_id, 'prev_target']  \n",
    "                    prev_emb_2 = users_meta.at[user_id, 'prev_emb_2']  \n",
    "                    prev_target_2 = users_meta.at[user_id, 'prev_target_2']  \n",
    "                    prev_emb_3 = users_meta.at[user_id, 'prev_emb_3']  \n",
    "                    prev_target_3 = users_meta.at[user_id, 'prev_target_3']  \n",
    "                    \n",
    "                    concatenated_emb = np.concatenate([prev_emb, [prev_target], prev_emb_2, [prev_target_2], prev_emb_3, [prev_target_3]])\n",
    "                    batch_embeddings.append(concatenated_emb)\n",
    "                    \n",
    "                embeddings = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "\n",
    "                batch_user_values = torch.tensor(batch_user_values, dtype=torch.long, device=device)\n",
    "                batch_item_values = torch.tensor(batch_item_values, dtype=torch.long, device=device)\n",
    "    \n",
    "                batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "                batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "                batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "                batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "         \n",
    "                batch_embeddings = torch.tensor(np.array(batch_embeddings), dtype=torch.float32, device=device)\n",
    "                \n",
    "                outputs = model(batch_user_values, \n",
    "                                batch_item_values, \n",
    "                                batch_source_values, \n",
    "                                batch_age_values, \n",
    "                                batch_duration_values, \n",
    "                                batch_gender_values, \n",
    "                                embeddings,\n",
    "                                batch_embeddings)\n",
    "                \n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                class_weights = torch.tensor([0, 1, 2], device=probabilities.device, dtype=probabilities.dtype)\n",
    "                weighted_predictions = torch.sum(probabilities * class_weights, dim=1).cpu().numpy()\n",
    "        \n",
    "                outputs_list.extend(weighted_predictions)\n",
    "\n",
    "##################################################################SAVE##################################################################\n",
    "    df_outputs = pd.DataFrame(outputs_list, columns=['predict'])\n",
    "    test_to_save['predict'] = df_outputs['predict']\n",
    "    output_path = f\"{CONFIG['test_pred_folder']}{CONFIG['test_output_path']}_e{epoch}.csv\"\n",
    "    test_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "    train_loss = train_running_loss / train_num_batches\n",
    "\n",
    "    print('Outputs saved at', output_path)\n",
    "    print(f\"Epoch [{epoch + 1}/{CONFIG['EPOCHS']}]: Train Loss: {train_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/test/7.11.5_test_e0.csv\n",
      "Epoch [1/1]: Train Loss: 0.127721\n"
     ]
    }
   ],
   "source": [
    "df_outputs = pd.DataFrame(outputs_list, columns=['predict'])\n",
    "test_to_save['predict'] = df_outputs['predict']\n",
    "output_path = f\"{CONFIG['test_pred_folder']}{CONFIG['test_output_path']}_e{epoch}.csv\"\n",
    "test_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "train_loss = train_running_loss / train_num_batches\n",
    "\n",
    "print('Outputs saved at', output_path)\n",
    "print(f\"Epoch [{epoch + 1}/{CONFIG['EPOCHS']}]: Train Loss: {train_loss:.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T14:41:47.307359Z",
     "start_time": "2024-12-18T14:41:45.336848200Z"
    }
   },
   "id": "961870755e3ee983",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id  item_id   predict\n0        1     7363  1.107743\n1        1    73770  1.171896\n2        1    75700  1.254958\n3        1    81204  1.118529\n4        1   110249  1.064205",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7363</td>\n      <td>1.107743</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>73770</td>\n      <td>1.171896</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>75700</td>\n      <td>1.254958</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>81204</td>\n      <td>1.118529</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>110249</td>\n      <td>1.064205</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_to_save.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T14:42:00.710375700Z",
     "start_time": "2024-12-18T14:42:00.663375300Z"
    }
   },
   "id": "73fbfdc215e847f6",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время работы deque: 0.005745 секунд\n",
      "Время работы numpy.roll: 0.816467 секунд\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Количество чисел для теста\n",
    "N = 100000\n",
    "maxlen = 3\n",
    "\n",
    "# --- Способ 1: Используем deque ---\n",
    "start_time_deque = time.time()\n",
    "history_deque = deque(maxlen=maxlen)\n",
    "for i in range(N):\n",
    "    history_deque.append(i)\n",
    "end_time_deque = time.time()\n",
    "\n",
    "time_deque = end_time_deque - start_time_deque\n",
    "\n",
    "# --- Способ 2: Используем numpy.roll ---\n",
    "start_time_roll = time.time()\n",
    "history_roll = np.zeros(maxlen, dtype=int)\n",
    "for i in range(N):\n",
    "    history_roll = np.roll(history_roll, -1)\n",
    "    history_roll[-1] = i\n",
    "end_time_roll = time.time()\n",
    "\n",
    "time_roll = end_time_roll - start_time_roll\n",
    "\n",
    "# Вывод результатов\n",
    "print(f\"Время работы deque: {time_deque:.6f} секунд\")\n",
    "print(f\"Время работы numpy.roll: {time_roll:.6f} секунд\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-18T15:11:25.200905300Z",
     "start_time": "2024-12-18T15:11:24.363689300Z"
    }
   },
   "id": "16f131123689cdda",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d17b29cb4c75db9f"
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 921.732176,
   "end_time": "2024-12-13T14:59:48.848043",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-13T14:44:27.115867",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
