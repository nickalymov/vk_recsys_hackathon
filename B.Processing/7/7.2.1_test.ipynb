{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cef5ce0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:01.280834900Z",
     "start_time": "2024-12-08T08:23:01.264939400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:23:53.484594Z",
     "iopub.status.busy": "2024-12-08T13:23:53.484244Z",
     "iopub.status.idle": "2024-12-08T13:23:53.491657Z",
     "shell.execute_reply": "2024-12-08T13:23:53.490991Z"
    },
    "papermill": {
     "duration": 0.013783,
     "end_time": "2024-12-08T13:23:53.493311",
     "exception": false,
     "start_time": "2024-12-08T13:23:53.479528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "number = '7.2.1'"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def compute_user_auc_numba(y_user_true, preds_user):\n",
    "    n = len(y_user_true)\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if y_user_true[i] < y_user_true[j]:\n",
    "                true_pair = 1\n",
    "                if preds_user[i] < preds_user[j]:\n",
    "                    pred_pair = 1\n",
    "                elif preds_user[i] == preds_user[j]:\n",
    "                    pred_pair = 0.5\n",
    "                else:\n",
    "                    pred_pair = 0\n",
    "            else:\n",
    "                true_pair = 0\n",
    "                pred_pair = 0\n",
    "\n",
    "            denominator += true_pair\n",
    "            numerator += true_pair * pred_pair\n",
    "\n",
    "    return numerator / denominator if denominator > 0 else 0\n",
    "\n",
    "\n",
    "def compute_auc_for_user(group):\n",
    "    trues = group['target'].values\n",
    "    preds = group['predict'].values\n",
    "\n",
    "    if len(set(trues)) < 2:\n",
    "        return None  \n",
    "\n",
    "    return compute_user_auc_numba(trues, preds)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7729d73b1ed3412"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba57652f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:01.297836Z",
     "start_time": "2024-12-08T08:23:01.281836200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:23:53.500485Z",
     "iopub.status.busy": "2024-12-08T13:23:53.499868Z",
     "iopub.status.idle": "2024-12-08T13:23:53.504822Z",
     "shell.execute_reply": "2024-12-08T13:23:53.504076Z"
    },
    "papermill": {
     "duration": 0.010088,
     "end_time": "2024-12-08T13:23:53.506388",
     "exception": false,
     "start_time": "2024-12-08T13:23:53.496300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_folder' : '/kaggle/input/vkrecsys/',\n",
    "    'val_pred_folder' : '/kaggle/working/',\n",
    "    'test_pred_folder' : '/kaggle/working/',\n",
    "    \n",
    "    'train_path' : 'train_interactions.parquet',\n",
    "    'test_path': 'test_pairs.csv',  \n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "    'folds_path' : 'fold.csv',\n",
    "    'val_output_path' : f'{number}_val',\n",
    "    'test_output_path' : f'{number}_test',\n",
    "    \n",
    "    'user_emb_size' : 256, \n",
    "    'item_emb_size' : 256, \n",
    "    'source_emb_size' : 256, \n",
    "    'age_emb_size' : 256, \n",
    "    'duration_emb_size' : 256, \n",
    "    'gender_emb_size' : 256, \n",
    "    \n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 16384,\n",
    "    'LR' : 0.001,\n",
    "    'EPOCHS' : 5,\n",
    "    'output_dim' : 3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f0a576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:03.516393300Z",
     "start_time": "2024-12-08T08:23:01.297836Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:23:53.512944Z",
     "iopub.status.busy": "2024-12-08T13:23:53.512404Z",
     "iopub.status.idle": "2024-12-08T13:23:57.349353Z",
     "shell.execute_reply": "2024-12-08T13:23:57.348434Z"
    },
    "papermill": {
     "duration": 3.8422,
     "end_time": "2024-12-08T13:23:57.351305",
     "exception": false,
     "start_time": "2024-12-08T13:23:53.509105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6485cef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:04.818133100Z",
     "start_time": "2024-12-08T08:23:04.807691900Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:23:57.358834Z",
     "iopub.status.busy": "2024-12-08T13:23:57.358492Z",
     "iopub.status.idle": "2024-12-08T13:23:57.419652Z",
     "shell.execute_reply": "2024-12-08T13:23:57.419008Z"
    },
    "papermill": {
     "duration": 0.066279,
     "end_time": "2024-12-08T13:23:57.421351",
     "exception": false,
     "start_time": "2024-12-08T13:23:57.355072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Device, torch decimal places and seed for reproducibility\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=40) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3225084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:31.162706400Z",
     "start_time": "2024-12-08T08:23:04.821137300Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:23:57.427644Z",
     "iopub.status.busy": "2024-12-08T13:23:57.427385Z",
     "iopub.status.idle": "2024-12-08T13:24:14.895766Z",
     "shell.execute_reply": "2024-12-08T13:24:14.895077Z"
    },
    "papermill": {
     "duration": 17.473764,
     "end_time": "2024-12-08T13:24:14.897750",
     "exception": false,
     "start_time": "2024-12-08T13:23:57.423986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['target'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['like', 'dislike'], inplace=True)\n",
    "train['target'] = train['target'].astype('int8')\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "test = pd.read_csv(f\"{CONFIG['data_folder']}{CONFIG['test_path']}\")\n",
    "test_to_save = test.copy()\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['duration'] = items_meta['duration'] - 5\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3417ae07",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:24:14.904317Z",
     "iopub.status.busy": "2024-12-08T13:24:14.904015Z",
     "iopub.status.idle": "2024-12-08T13:24:14.927374Z",
     "shell.execute_reply": "2024-12-08T13:24:14.926736Z"
    },
    "papermill": {
     "duration": 0.028434,
     "end_time": "2024-12-08T13:24:14.928981",
     "exception": false,
     "start_time": "2024-12-08T13:24:14.900547",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-13T14:39:44.204096800Z",
     "start_time": "2024-12-13T14:39:40.553928Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Model definition\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minit\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01minit\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mModel\u001B[39;00m(\u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mModule):\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \n\u001B[0;32m      6\u001B[0m                  input_dim, \n\u001B[0;32m      7\u001B[0m                  num_users\u001B[38;5;241m=\u001B[39musers_meta\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mnunique(), \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     13\u001B[0m                  output_dim\u001B[38;5;241m=\u001B[39mCONFIG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutput_dim\u001B[39m\u001B[38;5;124m'\u001B[39m], \n\u001B[0;32m     14\u001B[0m                  cin_layers\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m16\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m4\u001B[39m]):  \u001B[38;5;66;03m# Размеры слоев CIN\u001B[39;00m\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;28msuper\u001B[39m(Model, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# Model definition\n",
    "import torch.nn.init as init\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 num_ages=users_meta['age'].nunique(),\n",
    "                 num_durations=items_meta['duration'].nunique(),\n",
    "                 num_genders=users_meta['gender'].nunique(), \n",
    "                 output_dim=CONFIG['output_dim'], \n",
    "                 cin_layers=[16, 8, 4]):  # Размеры слоев CIN\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Embedding слои\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "\n",
    "        # Fully connected слои\n",
    "        self.fc1 = nn.Linear(input_dim + sum(cin_layers), 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 128)\n",
    "        self.fc5 = nn.Linear(128, 64)\n",
    "        self.fc6 = nn.Linear(64, 32)\n",
    "        self.fc7 = nn.Linear(32, 16)\n",
    "        self.fc8 = nn.Linear(16, 8)\n",
    "        self.fc9 = nn.Linear(8, output_dim)\n",
    "        \n",
    "        # CIN слои\n",
    "        self.cin_layers = nn.ModuleList()\n",
    "        prev_layer_size = input_dim\n",
    "        for layer_size in cin_layers:\n",
    "            self.cin_layers.append(nn.Conv1d(in_channels=prev_layer_size, \n",
    "                                             out_channels=layer_size, \n",
    "                                             kernel_size=1))\n",
    "            prev_layer_size = layer_size\n",
    "\n",
    "        # Активация\n",
    "        self.gelu = nn.GELU()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)  # Инициализация весов\n",
    "                if m.bias is not None:\n",
    "                    init.zeros_(m.bias)  # Инициализация биасов нулями\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids, embeddings):\n",
    "        # Embedding\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "        age_emb = self.age_embedding(age_ids)\n",
    "        duration_emb = self.duration_embedding(duration_ids)\n",
    "        gender_emb = self.gender_embedding(gender_ids)\n",
    "\n",
    "        # Конкатенация эмбеддингов\n",
    "        input_features = torch.cat((user_emb, item_emb, source_emb, age_emb, duration_emb, gender_emb, embeddings), dim=1)\n",
    "\n",
    "        # CIN\n",
    "        cin_outputs = []\n",
    "        x = input_features.unsqueeze(2)  # Добавляем ось для свертки\n",
    "        for cin_layer in self.cin_layers:\n",
    "            x = cin_layer(x)\n",
    "            x = self.gelu(x)\n",
    "            cin_outputs.append(x.sum(dim=2))  # Агрегация по оси фичей\n",
    "\n",
    "        cin_out = torch.cat(cin_outputs, dim=1)\n",
    "\n",
    "        # Полносвязные слои\n",
    "        x = torch.cat((input_features, cin_out), dim=1)\n",
    "        x = self.gelu(self.fc1(x))\n",
    "        x = self.gelu(self.fc2(x))\n",
    "        x = self.gelu(self.fc3(x))\n",
    "        x = self.gelu(self.fc4(x))\n",
    "        x = self.gelu(self.fc5(x))\n",
    "        x = self.gelu(self.fc6(x))\n",
    "        x = self.gelu(self.fc7(x))\n",
    "        x = self.gelu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c831f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:31.226732800Z",
     "start_time": "2024-12-08T08:23:31.212732200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:24:14.935150Z",
     "iopub.status.busy": "2024-12-08T13:24:14.934713Z",
     "iopub.status.idle": "2024-12-08T13:24:14.938710Z",
     "shell.execute_reply": "2024-12-08T13:24:14.937930Z"
    },
    "papermill": {
     "duration": 0.0087,
     "end_time": "2024-12-08T13:24:14.940248",
     "exception": false,
     "start_time": "2024-12-08T13:24:14.931548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input dimension\n",
    "input_dim = (CONFIG['user_emb_size'] + \n",
    "             CONFIG['item_emb_size'] + \n",
    "             CONFIG['source_emb_size'] + \n",
    "             CONFIG['age_emb_size'] +\n",
    "             CONFIG['duration_emb_size'] + \n",
    "             CONFIG['gender_emb_size'] + \n",
    "             32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ae16fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T08:23:35.561459600Z",
     "start_time": "2024-12-08T08:23:31.227732200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:24:14.946128Z",
     "iopub.status.busy": "2024-12-08T13:24:14.945882Z",
     "iopub.status.idle": "2024-12-08T13:24:17.775236Z",
     "shell.execute_reply": "2024-12-08T13:24:17.774238Z"
    },
    "papermill": {
     "duration": 2.834642,
     "end_time": "2024-12-08T13:24:17.777361",
     "exception": false,
     "start_time": "2024-12-08T13:24:14.942719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model, criterion and optimizer\n",
    "model = Model(input_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f664940",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T11:03:32.404670700Z",
     "start_time": "2024-12-08T08:23:35.576456600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-08T13:24:17.784801Z",
     "iopub.status.busy": "2024-12-08T13:24:17.784357Z",
     "iopub.status.idle": "2024-12-08T14:37:13.519752Z",
     "shell.execute_reply": "2024-12-08T14:37:13.518794Z"
    },
    "papermill": {
     "duration": 4378.935226,
     "end_time": "2024-12-08T14:37:16.715531",
     "exception": false,
     "start_time": "2024-12-08T13:24:17.780305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 8891/8891 [14:30<00:00, 10.22batch/s, train_mean_loss=0.133749]\n",
      "Epoch 1/5: 100%|██████████| 102/102 [00:05<00:00, 18.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at /kaggle/working/7.1.1_test_e0.csv\n",
      "Epoch [1/5]: Train Loss: 0.133749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|██████████| 8891/8891 [14:30<00:00, 10.21batch/s, train_mean_loss=0.124708]\n",
      "Epoch 2/5: 100%|██████████| 102/102 [00:05<00:00, 19.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at /kaggle/working/7.1.1_test_e1.csv\n",
      "Epoch [2/5]: Train Loss: 0.124708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|██████████| 8891/8891 [14:29<00:00, 10.23batch/s, train_mean_loss=0.123409]\n",
      "Epoch 3/5: 100%|██████████| 102/102 [00:05<00:00, 19.74batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at /kaggle/working/7.1.1_test_e2.csv\n",
      "Epoch [3/5]: Train Loss: 0.123409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|██████████| 8891/8891 [14:25<00:00, 10.27batch/s, train_mean_loss=0.121932]\n",
      "Epoch 4/5: 100%|██████████| 102/102 [00:05<00:00, 19.79batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at /kaggle/working/7.1.1_test_e3.csv\n",
      "Epoch [4/5]: Train Loss: 0.121932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|██████████| 8891/8891 [14:25<00:00, 10.28batch/s, train_mean_loss=0.119884]\n",
      "Epoch 5/5: 100%|██████████| 102/102 [00:05<00:00, 20.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs saved at /kaggle/working/7.1.1_test_e4.csv\n",
      "Epoch [5/5]: Train Loss: 0.119884\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "train_num_samples = len(train)\n",
    "train_num_batches = (train_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "test_num_samples = len(test)\n",
    "test_num_batches = (test_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "##################################################################TRAIN##################################################################\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    with tqdm(range(train_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], train_num_samples)\n",
    "            \n",
    "            batch_main = train.iloc[start_idx:end_idx]\n",
    "            \n",
    "            batch_user_values = batch_main['user_id'].values\n",
    "            batch_item_values = batch_main['item_id'].values\n",
    "\n",
    "            batch_users_meta = users_meta.loc[batch_user_values]\n",
    "            batch_items_meta = items_meta.loc[batch_item_values]\n",
    "\n",
    "            batch_user_values = torch.tensor(batch_user_values, dtype=torch.long, device=device)\n",
    "            batch_item_values = torch.tensor(batch_item_values, dtype=torch.long, device=device)\n",
    "\n",
    "            batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "            batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "            batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "            batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "\n",
    "            embeddings = torch.tensor(np.stack(batch_items_meta['embeddings'].values), device=device, dtype=torch.float32)\n",
    "            targets = torch.tensor(batch_main['target'].values, dtype=torch.long, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(batch_user_values, \n",
    "                            batch_item_values, \n",
    "                            batch_source_values, \n",
    "                            batch_age_values, \n",
    "                            batch_duration_values, \n",
    "                            batch_gender_values, \n",
    "                            embeddings)\n",
    "            \n",
    "            batch_loss = criterion(outputs, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += batch_loss.item()\n",
    "            t.set_postfix(train_mean_loss=f\"{train_running_loss / (batch_idx + 1):.6f}\")\n",
    "        \n",
    "##################################################################EVAL##################################################################\n",
    "    model.eval()\n",
    "    \n",
    "    outputs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(range(test_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as v:\n",
    "            for batch_idx in v:\n",
    "                start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "                end_idx = min(start_idx + CONFIG['BATCH_SIZE'], test_num_samples)\n",
    "                \n",
    "                batch_main = test.iloc[start_idx:end_idx]\n",
    "                \n",
    "                batch_user_values = batch_main['user_id'].values\n",
    "                batch_item_values = batch_main['item_id'].values\n",
    "    \n",
    "                batch_users_meta = users_meta.loc[batch_user_values]\n",
    "                batch_items_meta = items_meta.loc[batch_item_values]\n",
    "    \n",
    "                batch_user_values = torch.tensor(batch_user_values, dtype=torch.long, device=device)\n",
    "                batch_item_values = torch.tensor(batch_item_values, dtype=torch.long, device=device)\n",
    "    \n",
    "                batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "                batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "                batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "                batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "    \n",
    "                embeddings = torch.tensor(np.stack(batch_items_meta['embeddings'].values), device=device, dtype=torch.float32)\n",
    "                \n",
    "                outputs = model(batch_user_values, \n",
    "                            batch_item_values, \n",
    "                            batch_source_values, \n",
    "                            batch_age_values, \n",
    "                            batch_duration_values, \n",
    "                            batch_gender_values, \n",
    "                            embeddings)\n",
    "                \n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                class_weights = torch.tensor([0, 1, 2], device=probabilities.device, dtype=probabilities.dtype)\n",
    "                weighted_predictions = torch.sum(probabilities * class_weights, dim=1).cpu().numpy()\n",
    "        \n",
    "                outputs_list.extend(weighted_predictions)\n",
    "\n",
    "##################################################################SAVE##################################################################\n",
    "    df_outputs = pd.DataFrame(outputs_list, columns=['predict'])\n",
    "    test_to_save['predict'] = df_outputs['predict']\n",
    "    output_path = f\"{CONFIG['test_pred_folder']}{CONFIG['test_output_path']}_e{epoch}.csv\"\n",
    "    test_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "    train_loss = train_running_loss / train_num_batches\n",
    "\n",
    "    print('Outputs saved at', output_path)\n",
    "    print(f\"Epoch [{epoch + 1}/{CONFIG['EPOCHS']}]: Train Loss: {train_loss:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4410.421781,
   "end_time": "2024-12-08T14:37:21.480247",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-08T13:23:51.058466",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
