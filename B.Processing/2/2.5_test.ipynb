{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Загрузка необходимых библиотек\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:10.822530800Z",
     "start_time": "2024-11-24T04:45:09.120939100Z"
    }
   },
   "id": "35e4c5c3dcc3d65f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Устанавливаем устройство\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:12.074858700Z",
     "start_time": "2024-11-24T04:45:12.057735700Z"
    }
   },
   "id": "36163a7941728c88",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Параметры\n",
    "BATCH_SIZE = 16384\n",
    "model_path = '2.5_DCN_MLP.pth'\n",
    "test_path = 'fv2_test.parquet'  # Путь к тестовым данным\n",
    "custom_data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/custom_data/'\n",
    "data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/data/'\n",
    "test_output_path = '2.5_predictions.csv' "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:12.090860500Z",
     "start_time": "2024-11-24T04:45:12.075858800Z"
    }
   },
   "id": "76af81aa0633c882",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test = pd.read_parquet(f'{custom_data_folder}{test_path}', engine='pyarrow')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:12.136859900Z",
     "start_time": "2024-11-24T04:45:12.091859200Z"
    }
   },
   "id": "6ceb208e32a84ac6",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Загрузка метаинформации\n",
    "items_meta = pd.read_parquet(f'{data_folder}items_meta.parquet', engine='pyarrow')\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:12.423858700Z",
     "start_time": "2024-11-24T04:45:12.137859300Z"
    }
   },
   "id": "91e22496d03433be",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Преобразуем embeddings в массив и создаем индексы\n",
    "item_embeddings_array = torch.tensor(\n",
    "    np.stack(items_meta['embeddings'].values),\n",
    "    device=device,\n",
    "    dtype=torch.float32\n",
    ")\n",
    "item_id_to_index = {item: idx for idx, item in enumerate(items_meta.index)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:13.264551600Z",
     "start_time": "2024-11-24T04:45:12.423858700Z"
    }
   },
   "id": "5471d37ca34ddd0f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, interactions, device):\n",
    "        self.device = device\n",
    "        self.users = torch.tensor(interactions['user_id'].values, dtype=torch.long, device=self.device)\n",
    "        self.items = torch.tensor(interactions['item_id'].values, dtype=torch.long, device=self.device)\n",
    "        self.ages = torch.tensor(interactions['age'].values, dtype=torch.long, device=self.device)\n",
    "        self.item_durations = torch.tensor(interactions['item_duration'].values, dtype=torch.long, device=self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ages[idx], self.item_durations[idx]\n",
    "\n",
    "\n",
    "# Создаем DataLoader для тестовых данных\n",
    "test_ds = TestDataset(test, device)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:13.296550500Z",
     "start_time": "2024-11-24T04:45:13.264551600Z"
    }
   },
   "id": "306b31cc8dbc6b9d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DCN(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross_layers):\n",
    "        super(DCN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_cross_layers = num_cross_layers\n",
    "        \n",
    "        # Параметры для слоев пересечения\n",
    "        self.cross_weights = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim, 1)) for _ in range(num_cross_layers)]\n",
    "        )\n",
    "        self.cross_biases = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim)) for _ in range(num_cross_layers)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Инициализируем x0\n",
    "        x0 = x\n",
    "        for i in range(self.num_cross_layers):\n",
    "            x = x0 * (x @ self.cross_weights[i]) + self.cross_biases[i] + x\n",
    "        return x\n",
    "\n",
    "class DCNWithMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross_layers=3, hidden_dim=2048, output_dim=3):\n",
    "        super(DCNWithMLP, self).__init__()\n",
    "        \n",
    "        # Нормализация входных данных\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        # DCN модуль\n",
    "        self.dcn = DCN(input_dim, num_cross_layers)\n",
    "        \n",
    "        # MLP модуль\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.fc8 = nn.Linear(32, 16)\n",
    "        self.fc9 = nn.Linear(16, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Применяем нормализацию входных данных\n",
    "        x = self.batch_norm(x)\n",
    "        \n",
    "        # Пропускаем через DCN\n",
    "        x = self.dcn(x)\n",
    "        \n",
    "        # Пропускаем через MLP\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:13.309550700Z",
     "start_time": "2024-11-24T04:45:13.301550600Z"
    }
   },
   "id": "a4cd026eb08dd77d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Параметры модели\n",
    "input_dim = len(test.columns) + 32 # Включаем embeddings\n",
    "num_cross_layers = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:13.329550700Z",
     "start_time": "2024-11-24T04:45:13.312549700Z"
    }
   },
   "id": "1a7a4671ae687a89",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_2164\\3681416054.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": "DCNWithMLP(\n  (batch_norm): BatchNorm1d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dcn): DCN(\n    (cross_weights): ParameterList(  (0): Parameter containing: [torch.float32 of size 36x1 (cuda:0)])\n    (cross_biases): ParameterList(  (0): Parameter containing: [torch.float32 of size 36 (cuda:0)])\n  )\n  (fc1): Linear(in_features=36, out_features=2048, bias=True)\n  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n  (fc4): Linear(in_features=512, out_features=256, bias=True)\n  (fc5): Linear(in_features=256, out_features=128, bias=True)\n  (fc6): Linear(in_features=128, out_features=64, bias=True)\n  (fc7): Linear(in_features=64, out_features=32, bias=True)\n  (fc8): Linear(in_features=32, out_features=16, bias=True)\n  (fc9): Linear(in_features=16, out_features=3, bias=True)\n  (relu): ReLU()\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициализация модели и загрузка весов\n",
    "model = DCNWithMLP(input_dim, num_cross_layers).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:45:13.374551700Z",
     "start_time": "2024-11-24T04:45:13.328551200Z"
    }
   },
   "id": "17b45974b2df2d29",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 102/102 [01:07<00:00,  1.50batch/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for users, items, ages, item_durations in tqdm(test_dl, desc=\"Inference Progress\", unit=\"batch\"):\n",
    "        indices = [item_id_to_index[item.item()] for item in items]\n",
    "        embeddings = item_embeddings_array[indices]\n",
    "        \n",
    "        inputs = torch.cat((\n",
    "            users.unsqueeze(1),\n",
    "            items.unsqueeze(1),\n",
    "            ages.unsqueeze(1),\n",
    "            item_durations.unsqueeze(1),\n",
    "            embeddings\n",
    "        ), dim=1).float()\n",
    "        \n",
    "        outputs = model(inputs)  # Вероятности или сырые logits для каждого класса\n",
    "        \n",
    "        # Приводим logits к вероятностям (если это необходимо)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Веса для классов: 0, 1, 2\n",
    "        class_weights = torch.tensor([0, 1, 2], device=probabilities.device, dtype=probabilities.dtype)\n",
    "        \n",
    "        # Рассчитываем взвешенное значение\n",
    "        weighted_predictions = torch.sum(probabilities * class_weights, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_predictions.extend(weighted_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:46:21.470655300Z",
     "start_time": "2024-11-24T04:45:13.664803400Z"
    }
   },
   "id": "6b4361a1355f1e5d",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания сохранены в 2.5_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Сохранение предсказаний\n",
    "test['predict'] = all_predictions\n",
    "test.drop(columns=['age', 'item_duration'], inplace=True)\n",
    "test[['user_id', 'item_id', 'predict']].to_csv(f'{test_output_path}', index=False)\n",
    "print(f\"Предсказания сохранены в {test_output_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T04:46:23.292420700Z",
     "start_time": "2024-11-24T04:46:21.473651900Z"
    }
   },
   "id": "a1ffaabc9540130a",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
