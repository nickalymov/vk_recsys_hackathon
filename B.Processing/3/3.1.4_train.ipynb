{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377e8946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:12.773245700Z",
     "start_time": "2024-11-24T13:21:12.758230300Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:04.653799Z",
     "iopub.status.busy": "2024-11-26T14:28:04.653007Z",
     "iopub.status.idle": "2024-11-26T14:28:04.660981Z",
     "shell.execute_reply": "2024-11-26T14:28:04.660356Z"
    },
    "papermill": {
     "duration": 0.015605,
     "end_time": "2024-11-26T14:28:04.662645",
     "exception": false,
     "start_time": "2024-11-26T14:28:04.647040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "train_parquet = 'train_interactions.parquet'\n",
    "models_folder = '/kaggle/working/'\n",
    "model_path = '3.1.4_DCN_MLP.pth'\n",
    "custom_data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/custom_data/'\n",
    "orig_data_folder = '/kaggle/input/vkrecsys/'\n",
    "\n",
    "# model params\n",
    "BATCH_SIZE = 16384\n",
    "NUM_CROSS_LAYERS = 1\n",
    "LR = 0.001\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2dc57f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:14.421657Z",
     "start_time": "2024-11-24T13:21:12.764230600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:04.671630Z",
     "iopub.status.busy": "2024-11-26T14:28:04.670965Z",
     "iopub.status.idle": "2024-11-26T14:28:09.785178Z",
     "shell.execute_reply": "2024-11-26T14:28:09.784465Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 5.120734,
     "end_time": "2024-11-26T14:28:09.787293",
     "exception": false,
     "start_time": "2024-11-26T14:28:04.666559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb4c89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:15.057764300Z",
     "start_time": "2024-11-24T13:21:14.423586400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:09.797377Z",
     "iopub.status.busy": "2024-11-26T14:28:09.796460Z",
     "iopub.status.idle": "2024-11-26T14:28:09.866852Z",
     "shell.execute_reply": "2024-11-26T14:28:09.865919Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.077651,
     "end_time": "2024-11-26T14:28:09.869035",
     "exception": false,
     "start_time": "2024-11-26T14:28:09.791384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "torch.cuda.manual_seed_all(42)  \n",
    "np.random.seed(42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad9748de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:19.938511800Z",
     "start_time": "2024-11-24T13:21:15.056749300Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:09.880485Z",
     "iopub.status.busy": "2024-11-26T14:28:09.880168Z",
     "iopub.status.idle": "2024-11-26T14:28:26.699969Z",
     "shell.execute_reply": "2024-11-26T14:28:26.699270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 16.826628,
     "end_time": "2024-11-26T14:28:26.702025",
     "exception": false,
     "start_time": "2024-11-26T14:28:09.875397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(f'{orig_data_folder}{train_parquet}', engine='pyarrow')\n",
    "train['like'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['dislike'], inplace=True)\n",
    "train['like'] = train['like'].astype('int8')\n",
    "train.rename(columns={'like' : 'target'}, inplace=True)\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "items_meta = pd.read_parquet(f'{orig_data_folder}items_meta.parquet', engine='pyarrow')\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "# users_meta\n",
    "users_meta = pd.read_parquet(f'{orig_data_folder}users_meta.parquet', engine='pyarrow')\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['age'] = users_meta['age'].replace({1:0, 2:1})\n",
    "users_meta.set_index('user_id', inplace=True)\n",
    "\n",
    "# Преобразуем embeddings в словарь\n",
    "item_embeddings_dict = items_meta['embeddings'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4188ee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:19.954044100Z",
     "start_time": "2024-11-24T13:21:19.940517600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:26.711198Z",
     "iopub.status.busy": "2024-11-26T14:28:26.710523Z",
     "iopub.status.idle": "2024-11-26T14:28:26.715363Z",
     "shell.execute_reply": "2024-11-26T14:28:26.714534Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.011101,
     "end_time": "2024-11-26T14:28:26.716951",
     "exception": false,
     "start_time": "2024-11-26T14:28:26.705850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c46ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:19.970038600Z",
     "start_time": "2024-11-24T13:21:19.954044100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:26.725702Z",
     "iopub.status.busy": "2024-11-26T14:28:26.725432Z",
     "iopub.status.idle": "2024-11-26T14:28:26.729627Z",
     "shell.execute_reply": "2024-11-26T14:28:26.728740Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010401,
     "end_time": "2024-11-26T14:28:26.731251",
     "exception": false,
     "start_time": "2024-11-26T14:28:26.720850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_column(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e57dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:19.985047500Z",
     "start_time": "2024-11-24T13:21:19.970038600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:26.739477Z",
     "iopub.status.busy": "2024-11-26T14:28:26.739167Z",
     "iopub.status.idle": "2024-11-26T14:28:26.747066Z",
     "shell.execute_reply": "2024-11-26T14:28:26.746184Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014122,
     "end_time": "2024-11-26T14:28:26.748936",
     "exception": false,
     "start_time": "2024-11-26T14:28:26.734814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_meta['age'] = normalize_column(users_meta['age'])\n",
    "items_meta['duration'] = normalize_column(items_meta['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f66996cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:21.195410300Z",
     "start_time": "2024-11-24T13:21:19.985964600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:26.757479Z",
     "iopub.status.busy": "2024-11-26T14:28:26.757185Z",
     "iopub.status.idle": "2024-11-26T14:28:28.267081Z",
     "shell.execute_reply": "2024-11-26T14:28:28.266048Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.516667,
     "end_time": "2024-11-26T14:28:28.269281",
     "exception": false,
     "start_time": "2024-11-26T14:28:26.752614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_users = train['user_id'].nunique()\n",
    "num_items = train['item_id'].nunique()\n",
    "num_sources = items_meta['source_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c80d6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:22.003090800Z",
     "start_time": "2024-11-24T13:21:21.202913300Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:28.278193Z",
     "iopub.status.busy": "2024-11-26T14:28:28.277846Z",
     "iopub.status.idle": "2024-11-26T14:28:34.730797Z",
     "shell.execute_reply": "2024-11-26T14:28:34.729829Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 6.459951,
     "end_time": "2024-11-26T14:28:34.733196",
     "exception": false,
     "start_time": "2024-11-26T14:28:28.273245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_embedding = EmbeddingLayer(num_users, 1024).to(device)\n",
    "item_embedding = EmbeddingLayer(num_items, 1024).to(device)\n",
    "source_embedding = EmbeddingLayer(num_sources, 1024).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f34f40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:22.015997500Z",
     "start_time": "2024-11-24T13:21:22.007046300Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:34.742833Z",
     "iopub.status.busy": "2024-11-26T14:28:34.741774Z",
     "iopub.status.idle": "2024-11-26T14:28:34.746323Z",
     "shell.execute_reply": "2024-11-26T14:28:34.745506Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010777,
     "end_time": "2024-11-26T14:28:34.747883",
     "exception": false,
     "start_time": "2024-11-26T14:28:34.737106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = (1 + # gender\n",
    "             1 + # age\n",
    "             1 + # duration\n",
    "             user_embedding.embedding.embedding_dim + \n",
    "             item_embedding.embedding.embedding_dim + \n",
    "             source_embedding.embedding.embedding_dim +\n",
    "             32 # embeddings\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b3a4927",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:22.048996600Z",
     "start_time": "2024-11-24T13:21:22.023043400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:34.756375Z",
     "iopub.status.busy": "2024-11-26T14:28:34.756070Z",
     "iopub.status.idle": "2024-11-26T14:28:34.913607Z",
     "shell.execute_reply": "2024-11-26T14:28:34.912887Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.164032,
     "end_time": "2024-11-26T14:28:34.915608",
     "exception": false,
     "start_time": "2024-11-26T14:28:34.751576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DCN(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross_layers):\n",
    "        super(DCN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_cross_layers = num_cross_layers\n",
    "        \n",
    "        # Параметры для слоев пересечения\n",
    "        self.cross_weights = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim, 1)) for _ in range(num_cross_layers)]\n",
    "        )\n",
    "        self.cross_biases = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim)) for _ in range(num_cross_layers)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Инициализируем x0\n",
    "        x0 = x\n",
    "        for i in range(self.num_cross_layers):\n",
    "            x = x0 * (x @ self.cross_weights[i]) + self.cross_biases[i] + x\n",
    "        return x\n",
    "\n",
    "class DCNWithMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross_layers=3, hidden_dim=2048, output_dim=3):\n",
    "        super(DCNWithMLP, self).__init__()\n",
    "        \n",
    "        # Нормализация входных данных\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        # DCN модуль\n",
    "        self.dcn = DCN(input_dim, num_cross_layers)\n",
    "        \n",
    "        # MLP модуль\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)\n",
    "        self.fc6 = nn.Linear(512, 256)\n",
    "        self.fc7 = nn.Linear(256, 256)\n",
    "        self.fc8 = nn.Linear(256, 128)\n",
    "        self.fc9 = nn.Linear(128, output_dim)\n",
    "        self.softplus = nn.Softplus()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Применяем нормализацию входных данных\n",
    "        # x = self.batch_norm(x)\n",
    "        \n",
    "        # Пропускаем через DCN\n",
    "        # x = self.dcn(x)\n",
    "        \n",
    "        # Пропускаем через MLP\n",
    "        x = self.softplus(self.fc1(x))\n",
    "        x = self.softplus(self.fc2(x))\n",
    "        x = self.softplus(self.fc3(x))\n",
    "        x = self.softplus(self.fc4(x))\n",
    "        x = self.softplus(self.fc5(x))\n",
    "        x = self.softplus(self.fc6(x))\n",
    "        x = self.softplus(self.fc7(x))\n",
    "        x = self.softplus(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x\n",
    "\n",
    "# Определяем параметры\n",
    "num_cross_layers = NUM_CROSS_LAYERS  # Количество слоев DCN\n",
    "\n",
    "# Создаем модель\n",
    "model = DCNWithMLP(input_dim, num_cross_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cda6720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:22.797616500Z",
     "start_time": "2024-11-24T13:21:22.049997800Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:34.924052Z",
     "iopub.status.busy": "2024-11-26T14:28:34.923787Z",
     "iopub.status.idle": "2024-11-26T14:28:36.141848Z",
     "shell.execute_reply": "2024-11-26T14:28:36.141014Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.224646,
     "end_time": "2024-11-26T14:28:36.144085",
     "exception": false,
     "start_time": "2024-11-26T14:28:34.919439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Кросс-энтропийная функция потерь для многоклассовой классификации\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer = Adam(list(model.parameters()) +\n",
    "                 list(user_embedding.parameters()) +\n",
    "                 list(item_embedding.parameters()) +\n",
    "                 list(source_embedding.parameters()), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8a76495",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T13:21:23.031837Z",
     "start_time": "2024-11-24T13:21:22.802658900Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:36.153196Z",
     "iopub.status.busy": "2024-11-26T14:28:36.152713Z",
     "iopub.status.idle": "2024-11-26T14:28:36.504089Z",
     "shell.execute_reply": "2024-11-26T14:28:36.503335Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.358173,
     "end_time": "2024-11-26T14:28:36.506160",
     "exception": false,
     "start_time": "2024-11-26T14:28:36.147987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Преобразуем embeddings в массив и храним в tensor\n",
    "item_embeddings_array = torch.tensor(\n",
    "    np.stack(items_meta['embeddings'].values), \n",
    "    device=device, \n",
    "    dtype=torch.float32\n",
    ")\n",
    "\n",
    "# Сохраняем индексы для быстрого доступа\n",
    "item_id_to_index = {item: idx for idx, item in enumerate(items_meta.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9becdb3c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-24T13:21:23.041819600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T14:28:36.515786Z",
     "iopub.status.busy": "2024-11-26T14:28:36.515080Z",
     "iopub.status.idle": "2024-11-26T16:58:43.508045Z",
     "shell.execute_reply": "2024-11-26T16:58:43.507195Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 9007.000653,
     "end_time": "2024-11-26T16:58:43.510630",
     "exception": false,
     "start_time": "2024-11-26T14:28:36.509977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 8891/8891 [50:08<00:00,  2.96batch/s, batch_loss=0.129750, mean_loss=0.131508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Mean Loss: 0.1315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 8891/8891 [50:03<00:00,  2.96batch/s, batch_loss=0.126660, mean_loss=0.124317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Mean Loss: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 8891/8891 [49:54<00:00,  2.97batch/s, batch_loss=0.124052, mean_loss=0.121358]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Mean Loss: 0.1214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples = len(train)\n",
    "num_batches = (num_samples + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "user_embedding_weights_before = user_embedding.embedding.weight.clone().detach().cpu()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0  # Накопленный лосс для средней величины\n",
    "    with tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{EPOCHS}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(start_idx + BATCH_SIZE, num_samples)\n",
    "            \n",
    "            batch = train.iloc[start_idx:end_idx]\n",
    "\n",
    "            batch_user_ids = torch.tensor(batch['user_id'].values, dtype=torch.long, device=device)\n",
    "            batch_item_ids = torch.tensor(batch['item_id'].values, dtype=torch.long, device=device)\n",
    "            batch_source_ids = torch.tensor(items_meta.loc[batch['item_id'].values, 'source_id'].cat.codes.values, dtype=torch.long, device=device)\n",
    "            batch_age_ids = torch.tensor(users_meta.loc[batch['user_id'].values, 'age'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            batch_duration_ids = torch.tensor(items_meta.loc[batch['item_id'].values, 'duration'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            batch_gender_ids = torch.tensor(users_meta.loc[batch['user_id'].values, 'gender'].cat.codes.values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            user_emb = user_embedding(batch_user_ids)\n",
    "            item_emb = item_embedding(batch_item_ids)\n",
    "            source_emb = source_embedding(batch_source_ids)\n",
    "\n",
    "            item_indices = batch_item_ids.cpu().numpy()\n",
    "            embeddings = torch.tensor(\n",
    "                np.stack(items_meta.loc[item_indices, 'embeddings'].values), \n",
    "                device=device, \n",
    "                dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            inputs = torch.cat((\n",
    "                user_emb,\n",
    "                item_emb,\n",
    "                source_emb,\n",
    "                batch_age_ids,\n",
    "                batch_duration_ids,\n",
    "                batch_gender_ids,\n",
    "                embeddings\n",
    "            ), dim=1).float()\n",
    "\n",
    "            targets = torch.tensor(batch['target'].values, dtype=torch.long, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_loss = loss.item()  # Лосс для текущего батча\n",
    "            running_loss += batch_loss  # Накопление общего лосса\n",
    "\n",
    "            # Обновляем tqdm выводом текущего и среднего лосса\n",
    "            t.set_postfix(\n",
    "                batch_loss=f\"{batch_loss:.6f}\",\n",
    "                mean_loss=f\"{running_loss / (batch_idx + 1):.6f}\"\n",
    "            )  \n",
    "\n",
    "    # Средний лосс после эпохи\n",
    "    epoch_loss = running_loss / num_batches\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Mean Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47476c25",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T16:58:48.645324Z",
     "iopub.status.busy": "2024-11-26T16:58:48.644978Z",
     "iopub.status.idle": "2024-11-26T16:58:53.214328Z",
     "shell.execute_reply": "2024-11-26T16:58:53.213330Z"
    },
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.162996,
     "end_time": "2024-11-26T16:58:53.216266",
     "exception": false,
     "start_time": "2024-11-26T16:58:46.053270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель и эмбеддинги сохранены в /kaggle/working/3.1.4_DCN_MLP.pth\n"
     ]
    }
   ],
   "source": [
    "# Сохраняем обучаемую модель и эмбеддинги\n",
    "state = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"user_embedding_state_dict\": user_embedding.state_dict(),\n",
    "    \"item_embedding_state_dict\": item_embedding.state_dict(),\n",
    "    \"source_embedding_state_dict\": source_embedding.state_dict()\n",
    "}\n",
    "\n",
    "save_path = f'{models_folder}{model_path}'\n",
    "torch.save(state, save_path)\n",
    "print(f\"Модель и эмбеддинги сохранены в {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9055.052906,
   "end_time": "2024-11-26T16:58:57.230535",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T14:28:02.177629",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
