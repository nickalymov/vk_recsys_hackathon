{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4c275c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:30.718262Z",
     "start_time": "2024-11-26T18:12:30.713260400Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:44.254495Z",
     "iopub.status.busy": "2024-11-26T18:19:44.254160Z",
     "iopub.status.idle": "2024-11-26T18:19:44.261831Z",
     "shell.execute_reply": "2024-11-26T18:19:44.261186Z"
    },
    "papermill": {
     "duration": 0.013941,
     "end_time": "2024-11-26T18:19:44.263350",
     "exception": false,
     "start_time": "2024-11-26T18:19:44.249409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "train_parquet = 'train_interactions.parquet'\n",
    "models_folder = '/kaggle/working/'\n",
    "model_path = '3.1.5_MLP.pth'\n",
    "custom_data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/custom_data/'\n",
    "orig_data_folder = '/kaggle/input/vkrecsys/'\n",
    "folds_path = 'fold.csv'\n",
    "\n",
    "# model params\n",
    "BATCH_SIZE = 16384\n",
    "NUM_CROSS_LAYERS = 1\n",
    "LR = 0.001\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d0c997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:32.176347900Z",
     "start_time": "2024-11-26T18:12:30.720260400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:44.269625Z",
     "iopub.status.busy": "2024-11-26T18:19:44.269391Z",
     "iopub.status.idle": "2024-11-26T18:19:47.934358Z",
     "shell.execute_reply": "2024-11-26T18:19:47.933544Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.670253,
     "end_time": "2024-11-26T18:19:47.936406",
     "exception": false,
     "start_time": "2024-11-26T18:19:44.266153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ff0364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:33.440399300Z",
     "start_time": "2024-11-26T18:12:32.182356100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:47.943310Z",
     "iopub.status.busy": "2024-11-26T18:19:47.942911Z",
     "iopub.status.idle": "2024-11-26T18:19:48.004646Z",
     "shell.execute_reply": "2024-11-26T18:19:48.003956Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.067107,
     "end_time": "2024-11-26T18:19:48.006392",
     "exception": false,
     "start_time": "2024-11-26T18:19:47.939285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "torch.cuda.manual_seed_all(42)  \n",
    "np.random.seed(42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd515fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:38.108460300Z",
     "start_time": "2024-11-26T18:12:33.442430200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:48.013182Z",
     "iopub.status.busy": "2024-11-26T18:19:48.012875Z",
     "iopub.status.idle": "2024-11-26T18:20:05.312581Z",
     "shell.execute_reply": "2024-11-26T18:20:05.311844Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 17.305417,
     "end_time": "2024-11-26T18:20:05.314724",
     "exception": false,
     "start_time": "2024-11-26T18:19:48.009307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_parquet(f'{orig_data_folder}{train_parquet}', engine='pyarrow')\n",
    "train['like'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['dislike'], inplace=True)\n",
    "train['like'] = train['like'].astype('int8')\n",
    "train.rename(columns={'like' : 'target'}, inplace=True)\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "items_meta = pd.read_parquet(f'{orig_data_folder}items_meta.parquet', engine='pyarrow')\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "# users_meta\n",
    "users_meta = pd.read_parquet(f'{orig_data_folder}users_meta.parquet', engine='pyarrow')\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['age'] = users_meta['age'].replace({1:0, 2:1})\n",
    "users_meta.set_index('user_id', inplace=True)\n",
    "\n",
    "# Преобразуем embeddings в словарь\n",
    "item_embeddings_dict = items_meta['embeddings'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd610fd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:45.539872200Z",
     "start_time": "2024-11-26T18:12:38.113439100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:05.321504Z",
     "iopub.status.busy": "2024-11-26T18:20:05.321233Z",
     "iopub.status.idle": "2024-11-26T18:20:17.941193Z",
     "shell.execute_reply": "2024-11-26T18:20:17.940430Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.625576,
     "end_time": "2024-11-26T18:20:17.943287",
     "exception": false,
     "start_time": "2024-11-26T18:20:05.317711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = pd.read_csv(f'{orig_data_folder}fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "575d30b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:45.553043400Z",
     "start_time": "2024-11-26T18:12:45.536813600Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:17.951181Z",
     "iopub.status.busy": "2024-11-26T18:20:17.950882Z",
     "iopub.status.idle": "2024-11-26T18:20:17.954859Z",
     "shell.execute_reply": "2024-11-26T18:20:17.954045Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008933,
     "end_time": "2024-11-26T18:20:17.956443",
     "exception": false,
     "start_time": "2024-11-26T18:20:17.947510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_column(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd666948",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:45.567043800Z",
     "start_time": "2024-11-26T18:12:45.551111Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:17.962530Z",
     "iopub.status.busy": "2024-11-26T18:20:17.962284Z",
     "iopub.status.idle": "2024-11-26T18:20:17.969953Z",
     "shell.execute_reply": "2024-11-26T18:20:17.969376Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.012461,
     "end_time": "2024-11-26T18:20:17.971469",
     "exception": false,
     "start_time": "2024-11-26T18:20:17.959008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "users_meta['age'] = normalize_column(users_meta['age'])\n",
    "items_meta['duration'] = normalize_column(items_meta['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bbb6edb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:46.873785600Z",
     "start_time": "2024-11-26T18:12:45.566022Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:17.977655Z",
     "iopub.status.busy": "2024-11-26T18:20:17.977413Z",
     "iopub.status.idle": "2024-11-26T18:20:19.471064Z",
     "shell.execute_reply": "2024-11-26T18:20:19.470135Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1.499014,
     "end_time": "2024-11-26T18:20:19.473051",
     "exception": false,
     "start_time": "2024-11-26T18:20:17.974037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_users = train['user_id'].nunique()\n",
    "num_items = train['item_id'].nunique()\n",
    "num_sources = items_meta['source_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdeea22e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:12:46.897781200Z",
     "start_time": "2024-11-26T18:12:46.872791400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:19.479846Z",
     "iopub.status.busy": "2024-11-26T18:20:19.479339Z",
     "iopub.status.idle": "2024-11-26T18:20:19.488353Z",
     "shell.execute_reply": "2024-11-26T18:20:19.487532Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014069,
     "end_time": "2024-11-26T18:20:19.489950",
     "exception": false,
     "start_time": "2024-11-26T18:20:19.475881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_sources, input_dim, hidden_dim=2048, output_dim=3):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, 256)\n",
    "        self.item_embedding = nn.Embedding(num_items, 256)\n",
    "        self.source_embedding = nn.Embedding(num_sources, 256)\n",
    "        \n",
    "        # MLP модуль\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 1024)\n",
    "        self.fc4 = nn.Linear(1024, 512)\n",
    "        self.fc5 = nn.Linear(512, 512)\n",
    "        self.fc6 = nn.Linear(512, 256)\n",
    "        self.fc7 = nn.Linear(256, 256)\n",
    "        self.fc8 = nn.Linear(256, 128)\n",
    "        self.fc9 = nn.Linear(128, output_dim)\n",
    "        self.activation = nn.Softplus()\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age, duration, gender, embeddings):\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "\n",
    "        x = torch.cat((user_emb, item_emb, source_emb, age, duration, gender, embeddings), dim=1)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.activation(self.fc5(x))\n",
    "        x = self.activation(self.fc6(x))\n",
    "        x = self.activation(self.fc7(x))\n",
    "        x = self.activation(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x\n",
    "\n",
    "# Размер входных данных\n",
    "input_dim = 1 + 1 + 1 + 256 + 256 + 256 + 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef82c192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T18:14:42.534541700Z",
     "start_time": "2024-11-26T18:12:46.893815200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:19.496467Z",
     "iopub.status.busy": "2024-11-26T18:20:19.496224Z",
     "iopub.status.idle": "2024-11-26T22:43:34.806442Z",
     "shell.execute_reply": "2024-11-26T22:43:34.805520Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15795.315584,
     "end_time": "2024-11-26T22:43:34.808164",
     "exception": false,
     "start_time": "2024-11-26T18:20:19.492580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели для fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 (Fold 0): 100%|██████████| 6664/6664 [22:10<00:00,  5.01batch/s, mean_loss=0.138331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Fold 0, Loss: 0.1383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 (Fold 0): 100%|██████████| 6664/6664 [21:52<00:00,  5.08batch/s, mean_loss=0.125388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Fold 0, Loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 (Fold 0): 100%|██████████| 6664/6664 [21:47<00:00,  5.10batch/s, mean_loss=0.123699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Fold 0, Loss: 0.1237\n",
      "Модель для fold 0 сохранена в /kaggle/working/fold_0_3.1.5_MLP.pth\n",
      "VRAM очищена после fold 0.\n",
      "Обучение модели для fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 (Fold 1): 100%|██████████| 6667/6667 [21:49<00:00,  5.09batch/s, mean_loss=0.136219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Fold 1, Loss: 0.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 (Fold 1): 100%|██████████| 6667/6667 [21:45<00:00,  5.11batch/s, mean_loss=0.125394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Fold 1, Loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 (Fold 1): 100%|██████████| 6667/6667 [21:44<00:00,  5.11batch/s, mean_loss=0.123899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Fold 1, Loss: 0.1239\n",
      "Модель для fold 1 сохранена в /kaggle/working/fold_1_3.1.5_MLP.pth\n",
      "VRAM очищена после fold 1.\n",
      "Обучение модели для fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 (Fold 2): 100%|██████████| 6670/6670 [21:51<00:00,  5.09batch/s, mean_loss=0.135451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Fold 2, Loss: 0.1355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 (Fold 2): 100%|██████████| 6670/6670 [21:54<00:00,  5.07batch/s, mean_loss=0.125385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Fold 2, Loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 (Fold 2): 100%|██████████| 6670/6670 [21:52<00:00,  5.08batch/s, mean_loss=0.124018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Fold 2, Loss: 0.1240\n",
      "Модель для fold 2 сохранена в /kaggle/working/fold_2_3.1.5_MLP.pth\n",
      "VRAM очищена после fold 2.\n",
      "Обучение модели для fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 (Fold 3): 100%|██████████| 6673/6673 [21:53<00:00,  5.08batch/s, mean_loss=0.135774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Fold 3, Loss: 0.1358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 (Fold 3): 100%|██████████| 6673/6673 [21:57<00:00,  5.07batch/s, mean_loss=0.125414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Fold 3, Loss: 0.1254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 (Fold 3): 100%|██████████| 6673/6673 [21:55<00:00,  5.07batch/s, mean_loss=0.124055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Fold 3, Loss: 0.1241\n",
      "Модель для fold 3 сохранена в /kaggle/working/fold_3_3.1.5_MLP.pth\n",
      "VRAM очищена после fold 3.\n"
     ]
    }
   ],
   "source": [
    "import gc  # Для сборщика мусора\n",
    "\n",
    "for fold in range(4):\n",
    "    print(f\"Обучение модели для fold {fold}...\")\n",
    "    \n",
    "    # Разделение данных на train и validation\n",
    "    train_data = train[folds['fold'] != fold]\n",
    "    val_data = train[folds['fold'] == fold]\n",
    "    \n",
    "    # Создание новой модели для каждого fold\n",
    "    model = MLPModel(num_users, num_items, num_sources, input_dim).to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Обучение модели\n",
    "    num_samples = len(train_data)\n",
    "    num_batches = (num_samples + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{EPOCHS} (Fold {fold})\", unit=\"batch\") as t:\n",
    "            for batch_idx in t:\n",
    "                start_idx = batch_idx * BATCH_SIZE\n",
    "                end_idx = min(start_idx + BATCH_SIZE, num_samples)\n",
    "                batch = train_data.iloc[start_idx:end_idx]\n",
    "\n",
    "                batch_user_ids = torch.tensor(batch['user_id'].values, dtype=torch.long, device=device)\n",
    "                batch_item_ids = torch.tensor(batch['item_id'].values, dtype=torch.long, device=device)\n",
    "                batch_source_ids = torch.tensor(items_meta.loc[batch['item_id'].values, 'source_id'].cat.codes.values, dtype=torch.long, device=device)\n",
    "                batch_age = torch.tensor(users_meta.loc[batch['user_id'].values, 'age'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "                batch_duration = torch.tensor(items_meta.loc[batch['item_id'].values, 'duration'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "                batch_gender = torch.tensor(users_meta.loc[batch['user_id'].values, 'gender'].cat.codes.values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "                item_indices = batch_item_ids.cpu().numpy()\n",
    "                embeddings = torch.tensor(np.stack(items_meta.loc[item_indices, 'embeddings'].values), device=device, dtype=torch.float32)\n",
    "\n",
    "                targets = torch.tensor(batch['target'].values, dtype=torch.long, device=device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_user_ids, batch_item_ids, batch_source_ids, batch_age, batch_duration, batch_gender, embeddings)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                t.set_postfix(mean_loss=f\"{running_loss / (batch_idx + 1):.6f}\")\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Fold {fold}, Loss: {running_loss / num_batches:.4f}\")\n",
    "    \n",
    "    # Сохранение модели для текущего fold\n",
    "    fold_model_path = f\"{models_folder}fold_{fold}_{model_path}\"\n",
    "    torch.save({\"model_state_dict\": model.state_dict()}, fold_model_path)\n",
    "    print(f\"Модель для fold {fold} сохранена в {fold_model_path}\")\n",
    "\n",
    "    # Очистка VRAM\n",
    "    del model, optimizer, criterion  # Удаляем объекты модели и оптимизатора\n",
    "    torch.cuda.empty_cache()  # Очищаем видеопамять\n",
    "    gc.collect()  # Сбор мусора в системе\n",
    "    print(f\"VRAM очищена после fold {fold}.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15841.823616,
   "end_time": "2024-11-26T22:43:43.625098",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T18:19:41.801482",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
