{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Параметры\n",
    "BATCH_SIZE = 16384\n",
    "model_path = '3.1_DCN_MLP.pth'\n",
    "test_csv = 'test_pairs.csv'  # Путь к тестовым данным\n",
    "models_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/'\n",
    "custom_data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/custom_data/'\n",
    "data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/data/'\n",
    "test_output_path = '3.1_predictions.csv' \n",
    "results_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/'\n",
    "orig_data_folder = 'C:/Users/Николай/PycharmProjects/VKRecSys/data/'\n",
    "\n",
    "NUM_CROSS_LAYERS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:08:47.929204400Z",
     "start_time": "2024-11-24T16:08:47.909894400Z"
    }
   },
   "id": "85bb781765998480",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:00:20.533006Z",
     "start_time": "2024-11-24T16:00:19.108255800Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "test = pd.read_csv(f'{orig_data_folder}{test_csv}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:00:20.724642400Z",
     "start_time": "2024-11-24T16:00:20.534998200Z"
    }
   },
   "id": "4bb59b8372f36e7a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "items_meta = pd.read_parquet(f'{orig_data_folder}items_meta.parquet', engine='pyarrow')\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f'{orig_data_folder}users_meta.parquet', engine='pyarrow')\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['age'] = users_meta['age'].replace({1: 0, 2: 1})\n",
    "users_meta.set_index('user_id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:00:21.069206400Z",
     "start_time": "2024-11-24T16:00:20.728598100Z"
    }
   },
   "id": "a782ca772e252412",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def normalize_column(column):\n",
    "    return (column - column.min()) / (column.max() - column.min())\n",
    "\n",
    "\n",
    "users_meta['age'] = normalize_column(users_meta['age'])\n",
    "items_meta['duration'] = normalize_column(items_meta['duration'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:00:21.083204700Z",
     "start_time": "2024-11-24T16:00:21.072205800Z"
    }
   },
   "id": "1ade055158c8dd85",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "item_embeddings_dict = items_meta['embeddings'].to_dict()\n",
    "\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:04:12.064717300Z",
     "start_time": "2024-11-24T16:04:11.954744200Z"
    }
   },
   "id": "e89cecd2726e7216",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_5416\\605623018.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f'{models_folder}{model_path}', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "state = torch.load(f'{models_folder}{model_path}', map_location=device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:02:50.924293700Z",
     "start_time": "2024-11-24T16:02:50.773155500Z"
    }
   },
   "id": "47b1235a5fb37757",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_users = users_meta.index.nunique()\n",
    "num_items = items_meta.index.nunique()\n",
    "num_sources = items_meta['source_id'].nunique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:04:48.371257800Z",
     "start_time": "2024-11-24T16:04:48.334171500Z"
    }
   },
   "id": "bdf1f627719476c9",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<All keys matched successfully>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding = EmbeddingLayer(num_users, 32).to(device)\n",
    "user_embedding.load_state_dict(state['user_embedding_state_dict'])\n",
    "\n",
    "item_embedding = EmbeddingLayer(num_items, 32).to(device)\n",
    "item_embedding.load_state_dict(state['item_embedding_state_dict'])\n",
    "\n",
    "source_embedding = EmbeddingLayer(num_sources, 32).to(device)\n",
    "source_embedding.load_state_dict(state['source_embedding_state_dict'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:04:51.124353300Z",
     "start_time": "2024-11-24T16:04:50.960239800Z"
    }
   },
   "id": "d71944153521fe0b",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim = (1 + # gender\n",
    "             1 + # age\n",
    "             1 + # duration\n",
    "             user_embedding.embedding.embedding_dim + \n",
    "             item_embedding.embedding.embedding_dim + \n",
    "             source_embedding.embedding.embedding_dim +\n",
    "             32 # embeddings\n",
    "             )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:04:54.443340600Z",
     "start_time": "2024-11-24T16:04:54.422340100Z"
    }
   },
   "id": "1d24765ed80ce083",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DCN(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross_layers):\n",
    "        super(DCN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.num_cross_layers = num_cross_layers\n",
    "        \n",
    "        # Параметры для слоев пересечения\n",
    "        self.cross_weights = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim, 1)) for _ in range(num_cross_layers)]\n",
    "        )\n",
    "        self.cross_biases = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim)) for _ in range(num_cross_layers)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Инициализируем x0\n",
    "        x0 = x\n",
    "        for i in range(self.num_cross_layers):\n",
    "            x = x0 * (x @ self.cross_weights[i]) + self.cross_biases[i] + x\n",
    "        return x\n",
    "\n",
    "class DCNWithMLP(nn.Module):\n",
    "    def __init__(self, input_dim, num_cross_layers=3, hidden_dim=2048, output_dim=3):\n",
    "        super(DCNWithMLP, self).__init__()\n",
    "        \n",
    "        # Нормализация входных данных\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "        # DCN модуль\n",
    "        self.dcn = DCN(input_dim, num_cross_layers)\n",
    "        \n",
    "        # MLP модуль\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.fc8 = nn.Linear(32, 16)\n",
    "        self.fc9 = nn.Linear(16, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Применяем нормализацию входных данных\n",
    "        # x = self.batch_norm(x)\n",
    "        \n",
    "        # Пропускаем через DCN\n",
    "        x = self.dcn(x)\n",
    "        \n",
    "        # Пропускаем через MLP\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "        x = self.relu(self.fc5(x))\n",
    "        x = self.relu(self.fc6(x))\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x\n",
    "\n",
    "# Определяем параметры\n",
    "num_cross_layers = NUM_CROSS_LAYERS  # Количество слоев DCN"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:05:34.659409900Z",
     "start_time": "2024-11-24T16:05:34.645410700Z"
    }
   },
   "id": "2c96d1de0845a0f2",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DCNWithMLP(\n  (batch_norm): BatchNorm1d(131, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (dcn): DCN(\n    (cross_weights): ParameterList(  (0): Parameter containing: [torch.float32 of size 131x1 (cuda:0)])\n    (cross_biases): ParameterList(  (0): Parameter containing: [torch.float32 of size 131 (cuda:0)])\n  )\n  (fc1): Linear(in_features=131, out_features=2048, bias=True)\n  (fc2): Linear(in_features=2048, out_features=1024, bias=True)\n  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n  (fc4): Linear(in_features=512, out_features=256, bias=True)\n  (fc5): Linear(in_features=256, out_features=128, bias=True)\n  (fc6): Linear(in_features=128, out_features=64, bias=True)\n  (fc7): Linear(in_features=64, out_features=32, bias=True)\n  (fc8): Linear(in_features=32, out_features=16, bias=True)\n  (fc9): Linear(in_features=16, out_features=3, bias=True)\n  (relu): ReLU()\n)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DCNWithMLP(input_dim, NUM_CROSS_LAYERS).to(device)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:05:35.591433200Z",
     "start_time": "2024-11-24T16:05:35.541433700Z"
    }
   },
   "id": "c917f8f863b374b2",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_samples = len(test)\n",
    "num_batches = (num_samples + BATCH_SIZE - 1) // BATCH_SIZE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:05:55.864770900Z",
     "start_time": "2024-11-24T16:05:55.848772100Z"
    }
   },
   "id": "268c5ee4001ac683",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "predictions = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:05:58.823737500Z",
     "start_time": "2024-11-24T16:05:58.810742100Z"
    }
   },
   "id": "62de2c757d04e535",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 102/102 [00:20<00:00,  4.88batch/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with tqdm(range(num_batches), desc=\"Predicting\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(start_idx + BATCH_SIZE, num_samples)\n",
    "\n",
    "            batch = test.iloc[start_idx:end_idx]\n",
    "\n",
    "            batch_user_ids = torch.tensor(batch['user_id'].values, dtype=torch.long, device=device)\n",
    "            batch_item_ids = torch.tensor(batch['item_id'].values, dtype=torch.long, device=device)\n",
    "            batch_source_ids = torch.tensor(items_meta.loc[batch['item_id'].values, 'source_id'].cat.codes.values, dtype=torch.long, device=device)\n",
    "            batch_age_ids = torch.tensor(users_meta.loc[batch['user_id'].values, 'age'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            batch_duration_ids = torch.tensor(items_meta.loc[batch['item_id'].values, 'duration'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            batch_gender_ids = torch.tensor(users_meta.loc[batch['user_id'].values, 'gender'].cat.codes.values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            user_emb = user_embedding(batch_user_ids)\n",
    "            item_emb = item_embedding(batch_item_ids)\n",
    "            source_emb = source_embedding(batch_source_ids)\n",
    "\n",
    "            item_indices = batch_item_ids.cpu().numpy()\n",
    "            embeddings = torch.tensor(\n",
    "                np.stack(items_meta.loc[item_indices, 'embeddings'].values), \n",
    "                device=device, \n",
    "                dtype=torch.float32\n",
    "            )\n",
    "\n",
    "            inputs = torch.cat((\n",
    "                user_emb,\n",
    "                item_emb,\n",
    "                source_emb,\n",
    "                batch_age_ids,\n",
    "                batch_duration_ids,\n",
    "                batch_gender_ids,\n",
    "                embeddings\n",
    "            ), dim=1).float()\n",
    "\n",
    "            # Model inference\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "\n",
    "            # Weighted predictions\n",
    "            class_weights = torch.tensor([0, 1, 2], device=probabilities.device, dtype=probabilities.dtype)\n",
    "            weighted_predictions = torch.sum(probabilities * class_weights, dim=1).cpu().numpy()\n",
    "\n",
    "            predictions.extend(weighted_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:06:27.218074200Z",
     "start_time": "2024-11-24T16:06:06.286059Z"
    }
   },
   "id": "7b7b3c95aa155040",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test['predict'] = predictions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:06:27.406044300Z",
     "start_time": "2024-11-24T16:06:27.222948500Z"
    }
   },
   "id": "307b29ba095e0b98",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to f'C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/3.1_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "test.to_csv(f'{results_folder}{test_output_path}')\n",
    "print(f\"Predictions saved to f'{results_folder}{test_output_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-24T16:08:53.478789300Z",
     "start_time": "2024-11-24T16:08:50.824039Z"
    }
   },
   "id": "464d5d78adceb200",
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
