{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/data/',\n",
    "    'models_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/',\n",
    "    \n",
    "    'train_path' : 'train_interactions.parquet',\n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "    'model_path' : '4.2.pth',\n",
    "    \n",
    "    'user_emb_size' : 256, # 183404\n",
    "    'item_emb_size' : 256, # 337727\n",
    "    'source_emb_size' : 256, # 19613\n",
    "    'torch_precision' : 40, # number of decimal places for printing numbers\n",
    "    \n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 16384,\n",
    "    'LR' : 0.0001,\n",
    "    'EPOCHS' : 3,\n",
    "    'output_dim' : 3\n",
    "    \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:15.082115900Z",
     "start_time": "2024-11-28T14:40:15.063153Z"
    }
   },
   "id": "4a794a5c2901e728",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ee4882",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:17.459651Z",
     "iopub.status.busy": "2024-11-25T04:46:17.459331Z",
     "iopub.status.idle": "2024-11-25T04:46:22.363731Z",
     "shell.execute_reply": "2024-11-25T04:46:22.362971Z"
    },
    "papermill": {
     "duration": 4.91114,
     "end_time": "2024-11-25T04:46:22.365894",
     "exception": false,
     "start_time": "2024-11-25T04:46:17.454754",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:16.452954200Z",
     "start_time": "2024-11-28T14:40:15.085113100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf61865",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:22.376480Z",
     "iopub.status.busy": "2024-11-25T04:46:22.375606Z",
     "iopub.status.idle": "2024-11-25T04:46:22.445552Z",
     "shell.execute_reply": "2024-11-25T04:46:22.444304Z"
    },
    "papermill": {
     "duration": 0.077688,
     "end_time": "2024-11-25T04:46:22.448120",
     "exception": false,
     "start_time": "2024-11-25T04:46:22.370432",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:17.091701600Z",
     "start_time": "2024-11-28T14:40:16.454893500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Device and seed\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=CONFIG['torch_precision']) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dfa6723",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:22.463105Z",
     "iopub.status.busy": "2024-11-25T04:46:22.462120Z",
     "iopub.status.idle": "2024-11-25T04:46:36.958670Z",
     "shell.execute_reply": "2024-11-25T04:46:36.957928Z"
    },
    "papermill": {
     "duration": 14.504329,
     "end_time": "2024-11-25T04:46:36.960715",
     "exception": false,
     "start_time": "2024-11-25T04:46:22.456386",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:21.241464700Z",
     "start_time": "2024-11-28T14:40:17.090749700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['like'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['dislike'], inplace=True)\n",
    "train['like'] = train['like'].astype('int8')\n",
    "train.rename(columns={'like' : 'target'}, inplace=True)\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24430ed",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:36.983855Z",
     "iopub.status.busy": "2024-11-25T04:46:36.983176Z",
     "iopub.status.idle": "2024-11-25T04:46:36.986987Z",
     "shell.execute_reply": "2024-11-25T04:46:36.986337Z"
    },
    "papermill": {
     "duration": 0.009642,
     "end_time": "2024-11-25T04:46:36.988606",
     "exception": false,
     "start_time": "2024-11-25T04:46:36.978964",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:21.256300600Z",
     "start_time": "2024-11-28T14:40:21.244539200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalization of numeric features\n",
    "users_meta['age'] = (users_meta['age'] - users_meta['age'].min()) / (users_meta['age'].max() - users_meta['age'].min())\n",
    "items_meta['duration'] = (items_meta['duration'] - items_meta['duration'].min()) / (items_meta['duration'].max() - items_meta['duration'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769b210d304532d1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:21.275211100Z",
     "start_time": "2024-11-28T14:40:21.262218700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 output_dim=CONFIG['output_dim'],\n",
    "                 dropout_rate=0.2):  # Добавлен параметр dropout_rate\n",
    "        \n",
    "        super(MLPModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 256)\n",
    "        self.fc6 = nn.Linear(256, 128)\n",
    "        self.fc7 = nn.Linear(128, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)\n",
    "        self.fc9 = nn.Linear(64, output_dim)\n",
    "        \n",
    "        self.softplus = nn.Softplus()\n",
    "\n",
    "    def forward(self, user_ids, item_ids, source_ids, age, duration, gender, embeddings):\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "\n",
    "        x = torch.cat((user_emb, item_emb, source_emb, age, duration, gender, embeddings), dim=1)\n",
    "        \n",
    "        x = self.softplus(self.fc1(x))\n",
    "        \n",
    "        x = self.softplus(self.fc2(x))\n",
    "        \n",
    "        x = self.softplus(self.fc3(x))\n",
    "        \n",
    "        x = self.softplus(self.fc4(x))\n",
    "        \n",
    "        x = self.softplus(self.fc5(x))\n",
    "        \n",
    "        x = self.softplus(self.fc6(x))\n",
    "        \n",
    "        x = self.softplus(self.fc7(x))\n",
    "        \n",
    "        x = self.softplus(self.fc8(x))\n",
    "        \n",
    "        x = self.fc9(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Input dimension\n",
    "input_dim = 1 + 1 + 1 + CONFIG['user_emb_size'] + CONFIG['item_emb_size'] + CONFIG['source_emb_size'] + 32"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:40.338807Z",
     "iopub.status.busy": "2024-11-25T04:46:40.338514Z",
     "iopub.status.idle": "2024-11-25T04:46:40.342533Z",
     "shell.execute_reply": "2024-11-25T04:46:40.341740Z"
    },
    "papermill": {
     "duration": 0.010217,
     "end_time": "2024-11-25T04:46:40.344145",
     "exception": false,
     "start_time": "2024-11-25T04:46:40.333928",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:21.287229600Z",
     "start_time": "2024-11-28T14:40:21.273231300Z"
    }
   },
   "id": "0655459d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae46951b",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:40.465946Z",
     "iopub.status.busy": "2024-11-25T04:46:40.465691Z",
     "iopub.status.idle": "2024-11-25T04:46:41.656166Z",
     "shell.execute_reply": "2024-11-25T04:46:41.655167Z"
    },
    "papermill": {
     "duration": 1.197018,
     "end_time": "2024-11-25T04:46:41.658294",
     "exception": false,
     "start_time": "2024-11-25T04:46:40.461276",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T14:40:23.335074900Z",
     "start_time": "2024-11-28T14:40:21.289214500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model creation\n",
    "model = MLPModel(input_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5312a03",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T04:46:42.041350Z",
     "iopub.status.busy": "2024-11-25T04:46:42.041026Z",
     "iopub.status.idle": "2024-11-25T06:17:05.276364Z",
     "shell.execute_reply": "2024-11-25T06:17:05.275182Z"
    },
    "papermill": {
     "duration": 5423.242956,
     "end_time": "2024-11-25T06:17:05.279089",
     "exception": false,
     "start_time": "2024-11-25T04:46:42.036133",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T16:53:42.721277100Z",
     "start_time": "2024-11-28T14:40:23.340064800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 8891/8891 [44:49<00:00,  3.31batch/s, mean_loss=0.136550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 8891/8891 [44:39<00:00,  3.32batch/s, mean_loss=0.124516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.1245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 8891/8891 [43:50<00:00,  3.38batch/s, mean_loss=0.120124]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.1201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_samples = len(train)\n",
    "num_batches = (num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "lr_scheduler = OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=num_batches, epochs=CONFIG['EPOCHS'])\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    running_loss = 0.0\n",
    "    with tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], num_samples)\n",
    "            batch = train.iloc[start_idx:end_idx]\n",
    "\n",
    "            batch_user_ids = torch.tensor(batch['user_id'].values, dtype=torch.long, device=device)\n",
    "            batch_item_ids = torch.tensor(batch['item_id'].values, dtype=torch.long, device=device)\n",
    "            batch_source_ids = torch.tensor(items_meta.loc[batch['item_id'].values, 'source_id'].cat.codes.values, dtype=torch.long, device=device)\n",
    "            batch_age = torch.tensor(users_meta.loc[batch['user_id'].values, 'age'].values, dtype=torch.float32, device=device).unsqueeze(1)    \n",
    "            batch_duration = torch.tensor(items_meta.loc[batch['item_id'].values, 'duration'].values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            batch_gender = torch.tensor(users_meta.loc[batch['user_id'].values, 'gender'].cat.codes.values, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            item_indices = batch_item_ids.cpu().numpy()\n",
    "            embeddings = torch.tensor(np.stack(items_meta.loc[item_indices, 'embeddings'].values), device=device, dtype=torch.float32)\n",
    "\n",
    "            targets = torch.tensor(batch['target'].values, dtype=torch.long, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_user_ids, batch_item_ids, batch_source_ids, batch_age, batch_duration, batch_gender, embeddings)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            lr_scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            t.set_postfix(mean_loss=f\"{running_loss / (batch_idx + 1):.6f}\")\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{CONFIG['EPOCHS']}], Loss: {running_loss / num_batches:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "812445df",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T06:17:10.412189Z",
     "iopub.status.busy": "2024-11-25T06:17:10.411827Z",
     "iopub.status.idle": "2024-11-25T06:17:11.585194Z",
     "shell.execute_reply": "2024-11-25T06:17:11.584275Z"
    },
    "papermill": {
     "duration": 3.735999,
     "end_time": "2024-11-25T06:17:11.587001",
     "exception": false,
     "start_time": "2024-11-25T06:17:07.851002",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-11-28T16:53:43.794801200Z",
     "start_time": "2024-11-28T16:53:42.718237100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в f'C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/4.2.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save model_state  \n",
    "torch.save({\"model_state_dict\": model.state_dict()}, f\"{CONFIG['models_folder']}{CONFIG['model_path']}\")\n",
    "print(f\"Модель сохранена в f'{CONFIG['models_folder']}{CONFIG['model_path']}'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5460.653933,
   "end_time": "2024-11-25T06:17:15.604943",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-25T04:46:14.951010",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
