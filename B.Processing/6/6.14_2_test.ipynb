{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de76b33d4673490",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:34.144139200Z",
     "start_time": "2024-12-08T06:34:34.126122900Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_folder': 'C:/Users/Николай/PycharmProjects/VKRecSys/data/',\n",
    "    'models_folder': 'C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/',\n",
    "    'results_folder': 'C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/',\n",
    "\n",
    "    'test_path': 'test_pairs.csv',  \n",
    "    'model_path': '6.14_2.pth', \n",
    "    'output_path': '6.14_2_predictions.csv',\n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "\n",
    "    'user_emb_size' : 256, # 183404\n",
    "    'item_emb_size' : 256, # 337727\n",
    "    'source_emb_size' : 256, # 19613\n",
    "    'age_emb_size' : 256, # 43\n",
    "    'duration_emb_size' : 256, # ~175   \n",
    "    'gender_emb_size' : 256, # 3\n",
    "    'torch_precision' : 40, # number of decimal places for printing numbers\n",
    "\n",
    "    'DEVICE': 'cuda',\n",
    "    'SEED': 42,\n",
    "    'BATCH_SIZE': 16384,\n",
    "    'output_dim': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:35.819809Z",
     "start_time": "2024-12-08T06:34:34.132631800Z"
    }
   },
   "id": "2af2aecfc6847170",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=CONFIG['torch_precision'])\n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])\n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])\n",
    "np.random.seed(CONFIG['SEED'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:36.485841300Z",
     "start_time": "2024-12-08T06:34:36.466841100Z"
    }
   },
   "id": "404582cb35e90296",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{CONFIG['data_folder']}{CONFIG['test_path']}\")\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['duration'] = items_meta['duration'] - 5\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta['duration'] = items_meta['duration'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['age'] = users_meta['age'].astype('category')\n",
    "users_meta.set_index('user_id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:37.077155400Z",
     "start_time": "2024-12-08T06:34:36.488841200Z"
    }
   },
   "id": "75461867fc71ecda",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 num_ages=users_meta['age'].nunique(),\n",
    "                 num_durations=items_meta['duration'].nunique(),\n",
    "                 num_genders=users_meta['gender'].nunique(), \n",
    "                 output_dim=CONFIG['output_dim']): \n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # Embedding layers for each feature\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 256)\n",
    "        self.fc6 = nn.Linear(256, 128)\n",
    "        self.fc7 = nn.Linear(128, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)\n",
    "        self.target_output = nn.Linear(64, output_dim)\n",
    "        self.share_output = nn.Linear(64, 1)\n",
    "        self.bookmark_output = nn.Linear(64, 1)\n",
    "        self.timespent_output = nn.Linear(64, 255)\n",
    "        \n",
    "        self.gelu = nn.GELU()\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids, embeddings):\n",
    "        \n",
    "        # Obtain embeddings for all features\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "        age_emb = self.age_embedding(age_ids)\n",
    "        duration_emb = self.duration_embedding(duration_ids)\n",
    "        gender_emb = self.gender_embedding(gender_ids)\n",
    "        \n",
    "        x = torch.cat((user_emb, item_emb, source_emb, age_emb, duration_emb, gender_emb, embeddings), dim=1)\n",
    "        \n",
    "        x = self.gelu(self.fc1(x))\n",
    "        \n",
    "        x = self.gelu(self.fc2(x))\n",
    "        \n",
    "        x = self.gelu(self.fc3(x))\n",
    "        \n",
    "        x = self.gelu(self.fc4(x))\n",
    "        \n",
    "        x = self.gelu(self.fc5(x))\n",
    "        \n",
    "        x = self.gelu(self.fc6(x))\n",
    "        \n",
    "        x = self.gelu(self.fc7(x))\n",
    "        \n",
    "        x = self.gelu(self.fc8(x))\n",
    "        \n",
    "        target_output = self.target_output(x)\n",
    "        share_output = self.share_output(x)\n",
    "        bookmark_output = self.bookmark_output(x)\n",
    "        timespent_output = self.timespent_output(x)\n",
    "        \n",
    "        return target_output, share_output, bookmark_output, timespent_output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:37.110170300Z",
     "start_time": "2024-12-08T06:34:37.088773700Z"
    }
   },
   "id": "a8659ecba5b8dcca",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_dim = (CONFIG['user_emb_size'] + \n",
    "             CONFIG['item_emb_size'] + \n",
    "             CONFIG['source_emb_size'] + \n",
    "             CONFIG['age_emb_size'] +\n",
    "             CONFIG['duration_emb_size'] + \n",
    "             CONFIG['gender_emb_size'] + \n",
    "             32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:37.124170200Z",
     "start_time": "2024-12-08T06:34:37.109170300Z"
    }
   },
   "id": "f37b42fb9a81929b",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Николай\\AppData\\Local\\Temp\\ipykernel_21648\\2686595169.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f\"{CONFIG['models_folder']}{CONFIG['model_path']}\")['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "Model(\n  (user_embedding): Embedding(183404, 256)\n  (item_embedding): Embedding(337727, 256)\n  (source_embedding): Embedding(19613, 256)\n  (age_embedding): Embedding(43, 256)\n  (duration_embedding): Embedding(176, 256)\n  (gender_embedding): Embedding(2, 256)\n  (fc1): Linear(in_features=1568, out_features=1024, bias=True)\n  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n  (fc4): Linear(in_features=512, out_features=256, bias=True)\n  (fc5): Linear(in_features=256, out_features=256, bias=True)\n  (fc6): Linear(in_features=256, out_features=128, bias=True)\n  (fc7): Linear(in_features=128, out_features=128, bias=True)\n  (fc8): Linear(in_features=128, out_features=64, bias=True)\n  (target_output): Linear(in_features=64, out_features=3, bias=True)\n  (share_output): Linear(in_features=64, out_features=1, bias=True)\n  (bookmark_output): Linear(in_features=64, out_features=1, bias=True)\n  (timespent_output): Linear(in_features=64, out_features=255, bias=True)\n  (gelu): GELU(approximate='none')\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_dim).to(device)\n",
    "model.load_state_dict(torch.load(f\"{CONFIG['models_folder']}{CONFIG['model_path']}\")['model_state_dict'])\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:38.951782500Z",
     "start_time": "2024-12-08T06:34:37.129170600Z"
    }
   },
   "id": "92808a74f0ca9b8",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 102/102 [00:09<00:00, 10.26batch/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "num_samples = len(test)\n",
    "num_batches = (num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Predicting\", unit=\"batch\"):\n",
    "        start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "        end_idx = min(start_idx + CONFIG['BATCH_SIZE'], num_samples)\n",
    "        batch_main = test.iloc[start_idx:end_idx]\n",
    "        batch_user_ids = batch_main['user_id'].values\n",
    "        batch_item_ids = batch_main['item_id'].values\n",
    "        \n",
    "        batch_users_meta = users_meta.loc[batch_user_ids]\n",
    "        batch_items_meta = items_meta.loc[batch_item_ids]\n",
    "        \n",
    "        batch_user_values = torch.tensor(batch_user_ids, dtype=torch.long, device=device)\n",
    "        batch_item_values = torch.tensor(batch_item_ids, dtype=torch.long, device=device)\n",
    "        \n",
    "        batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "        batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "        batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "        batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "\n",
    "        embeddings = torch.tensor(np.stack(batch_items_meta['embeddings'].values), device=device, dtype=torch.float32)\n",
    "\n",
    "        target_outputs, share_outputs, bookmark_outputs, timespent_outputs = model(batch_user_values,\n",
    "                                                                                       batch_item_values, \n",
    "                                                                                       batch_source_values,\n",
    "                                                                                       batch_age_values, \n",
    "                                                                                       batch_duration_values, \n",
    "                                                                                       batch_gender_values, \n",
    "                                                                                       embeddings)\n",
    "        probabilities = F.softmax(target_outputs, dim=1)\n",
    "\n",
    "        # Взвешенные предсказания\n",
    "        class_weights = torch.tensor([0, 1, 2], device=probabilities.device, dtype=probabilities.dtype)\n",
    "        weighted_predictions = torch.sum(probabilities * class_weights, dim=1).cpu().numpy()\n",
    "\n",
    "        predictions.extend(weighted_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:48.900943100Z",
     "start_time": "2024-12-08T06:34:38.939758300Z"
    }
   },
   "id": "d3a3fa8ef64050c9",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to f'C:/Users/Николай/PycharmProjects/VKRecSys/C.Results/6.14_2_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Добавление предсказанных значений в DataFrame\n",
    "test['predict'] = predictions\n",
    "\n",
    "test.to_csv(f\"{CONFIG['results_folder']}{CONFIG['output_path']}\", index=False)\n",
    "print(f\"Predictions saved to f'{CONFIG['results_folder']}{CONFIG['output_path']}'\")"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T06:34:50.926913400Z",
     "start_time": "2024-12-08T06:34:48.902944Z"
    }
   },
   "id": "initial_id",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
