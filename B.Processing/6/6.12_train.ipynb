{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1483c50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:11.760439700Z",
     "start_time": "2024-12-06T04:34:11.737439900Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:07.544775Z",
     "iopub.status.busy": "2024-12-06T14:06:07.543917Z",
     "iopub.status.idle": "2024-12-06T14:06:07.552950Z",
     "shell.execute_reply": "2024-12-06T14:06:07.552335Z"
    },
    "papermill": {
     "duration": 0.015865,
     "end_time": "2024-12-06T14:06:07.554549",
     "exception": false,
     "start_time": "2024-12-06T14:06:07.538684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_folder' : '/kaggle/input/vkrecsys/',\n",
    "    'models_folder' : '/kaggle/working/',\n",
    "    \n",
    "    'train_path' : 'train_interactions.parquet',\n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "    'model_path' : '6.12.pth',\n",
    "    \n",
    "    'user_emb_size' : 256, # 183404\n",
    "    'item_emb_size' : 256, # 337727\n",
    "    'source_emb_size' : 256, # 19613\n",
    "    'age_emb_size' : 256, # 43\n",
    "    'duration_emb_size' : 256, # ~175   \n",
    "    'gender_emb_size' : 256, # 3\n",
    "    'timespent_emb_size' : 256, # 43\n",
    "    'torch_precision' : 40, # number of decimal places for printing numbers\n",
    "    \n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 16384,\n",
    "    'LR' : 0.001,\n",
    "    'EPOCHS' : 3,\n",
    "    'output_dim' : 3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3544f306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:13.156688700Z",
     "start_time": "2024-12-06T04:34:11.762440100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:07.562157Z",
     "iopub.status.busy": "2024-12-06T14:06:07.561442Z",
     "iopub.status.idle": "2024-12-06T14:06:11.507131Z",
     "shell.execute_reply": "2024-12-06T14:06:11.506238Z"
    },
    "papermill": {
     "duration": 3.951906,
     "end_time": "2024-12-06T14:06:11.509422",
     "exception": false,
     "start_time": "2024-12-06T14:06:07.557516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f5bc1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:13.794085Z",
     "start_time": "2024-12-06T04:34:13.777071100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:11.517134Z",
     "iopub.status.busy": "2024-12-06T14:06:11.516600Z",
     "iopub.status.idle": "2024-12-06T14:06:11.592955Z",
     "shell.execute_reply": "2024-12-06T14:06:11.592133Z"
    },
    "papermill": {
     "duration": 0.081876,
     "end_time": "2024-12-06T14:06:11.594464",
     "exception": false,
     "start_time": "2024-12-06T14:06:11.512588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Device and seed\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=CONFIG['torch_precision']) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec46d3a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:18.286382800Z",
     "start_time": "2024-12-06T04:34:13.801085400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:11.601577Z",
     "iopub.status.busy": "2024-12-06T14:06:11.601207Z",
     "iopub.status.idle": "2024-12-06T14:06:27.157832Z",
     "shell.execute_reply": "2024-12-06T14:06:27.156811Z"
    },
    "papermill": {
     "duration": 15.562691,
     "end_time": "2024-12-06T14:06:27.160054",
     "exception": false,
     "start_time": "2024-12-06T14:06:11.597363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['target'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['like', 'dislike'], inplace=True)\n",
    "train['target'] = train['target'].astype('int8')\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "train['timespent'] = train['timespent'] - 1\n",
    "conditions = [\n",
    "    train['timespent'] < 85,          # Значения меньше 85\n",
    "    train['timespent'] < 170,         # Значения от 85 до 169 (включая)\n",
    "    train['timespent'] >= 170         # Остальные (170 и выше)\n",
    "]\n",
    "\n",
    "# Соответствующие значения\n",
    "choices = [0, 1, 2]\n",
    "\n",
    "# Применяем условия\n",
    "train['timespent'] = np.select(conditions, choices)\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['duration'] = items_meta['duration'] - 5\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta['duration'] = items_meta['duration'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['age'] = users_meta['age'].astype('category')\n",
    "users_meta.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b76abc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:26.817598200Z",
     "start_time": "2024-12-06T04:34:25.110141200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:27.167120Z",
     "iopub.status.busy": "2024-12-06T14:06:27.166820Z",
     "iopub.status.idle": "2024-12-06T14:06:27.950505Z",
     "shell.execute_reply": "2024-12-06T14:06:27.949341Z"
    },
    "papermill": {
     "duration": 0.789795,
     "end_time": "2024-12-06T14:06:27.952928",
     "exception": false,
     "start_time": "2024-12-06T14:06:27.163133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AFMModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 num_ages=users_meta['age'].nunique(),\n",
    "                 num_durations=items_meta['duration'].nunique(),\n",
    "                 num_genders=users_meta['gender'].nunique(), \n",
    "                 num_timespents=train['timespent'].nunique(),\n",
    "                 output_dim=CONFIG['output_dim']): \n",
    "        super(AFMModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for each feature\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "        self.timespent_embedding = nn.Embedding(num_timespents, CONFIG['timespent_emb_size'])\n",
    "\n",
    "        # Transformations for embeddings\n",
    "        self.user_emb_transform = nn.Linear(CONFIG['user_emb_size'], 32)\n",
    "        self.item_emb_transform = nn.Linear(CONFIG['item_emb_size'], 32)\n",
    "        self.source_emb_transform = nn.Linear(CONFIG['source_emb_size'], 32)\n",
    "        self.age_emb_transform = nn.Linear(CONFIG['age_emb_size'], 32)\n",
    "        self.duration_emb_transform = nn.Linear(CONFIG['duration_emb_size'], 32)\n",
    "        self.gender_emb_transform = nn.Linear(CONFIG['gender_emb_size'], 32)\n",
    "        self.timespent_emb_transform = nn.Linear(CONFIG['timespent_emb_size'], 32)\n",
    "\n",
    "        # Attention layer components\n",
    "        self.attention_network = nn.Sequential(\n",
    "            nn.Linear(64, 32),  # 64 comes from the concatenation of two embedding sizes\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(32, output_dim)  # Output layer\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.fc5 = nn.Linear(256, 256)\n",
    "        self.fc6 = nn.Linear(256, 128)\n",
    "        self.fc7 = nn.Linear(128, 128)\n",
    "        self.fc8 = nn.Linear(128, 64)\n",
    "        self.fc9 = nn.Linear(64, output_dim)\n",
    "        \n",
    "        self.gelu = nn.GELU()\n",
    "    \n",
    "    def pairwise_interaction(self, x1, x2):\n",
    "        return x1 * x2  # Element-wise multiplication for feature interaction\n",
    "    \n",
    "    def compute_attention(self, emb1, emb2):\n",
    "        # Concatenate embeddings of the pair of features and pass through attention network\n",
    "        combined_emb = torch.cat([emb1, emb2], dim=-1)  # Concatenate embeddings (dim=-1 is feature dimension)\n",
    "        attention_score = self.attention_network(combined_emb)\n",
    "        attention_score = torch.sigmoid(attention_score)  # Use sigmoid for attention score\n",
    "        return attention_score\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids, embeddings, timespent_ids):\n",
    "        \n",
    "        # Obtain embeddings for all features\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "        age_emb = self.age_embedding(age_ids)\n",
    "        duration_emb = self.duration_embedding(duration_ids)\n",
    "        gender_emb = self.gender_embedding(gender_ids)\n",
    "        timespent_emb = self.timespent_embedding(timespent_ids)\n",
    "        \n",
    "        x = torch.cat((user_emb, item_emb, source_emb, age_emb, duration_emb, gender_emb, embeddings, timespent_emb), dim=1)\n",
    "        \n",
    "        x = self.gelu(self.fc1(x))\n",
    "        \n",
    "        x = self.gelu(self.fc2(x))\n",
    "        \n",
    "        x = self.gelu(self.fc3(x))\n",
    "        \n",
    "        x = self.gelu(self.fc4(x))\n",
    "        \n",
    "        x = self.gelu(self.fc5(x))\n",
    "        \n",
    "        x = self.gelu(self.fc6(x))\n",
    "        \n",
    "        x = self.gelu(self.fc7(x))\n",
    "        \n",
    "        x = self.gelu(self.fc8(x))\n",
    "        \n",
    "        x = self.fc9(x)\n",
    "        \n",
    "        # Apply linear transformations to embeddings\n",
    "        user_emb = self.user_emb_transform(user_emb)\n",
    "        item_emb = self.item_emb_transform(item_emb)\n",
    "        source_emb = self.source_emb_transform(source_emb)\n",
    "        age_emb = self.age_emb_transform(age_emb)\n",
    "        duration_emb = self.duration_emb_transform(duration_emb)\n",
    "        gender_emb = self.gender_emb_transform(gender_emb)\n",
    "        timespent_emb = self.timespent_emb_transform(timespent_emb)\n",
    "        \n",
    "        # Create dictionary of all embeddings\n",
    "        embeddings_dict = {\n",
    "            'user': user_emb,\n",
    "            'item': item_emb,\n",
    "            'source': source_emb,\n",
    "            'age': age_emb,\n",
    "            'duration': duration_emb,\n",
    "            'gender': gender_emb,\n",
    "            'embeddings': embeddings,\n",
    "            'timespent': timespent_emb,\n",
    "        }\n",
    "        \n",
    "        interactions = []\n",
    "        attention_scores = []\n",
    "        \n",
    "        # Compute pairwise interactions and their attention scores\n",
    "        for key1, emb1 in embeddings_dict.items():\n",
    "            for key2, emb2 in embeddings_dict.items():\n",
    "                if key1 < key2:  # Avoid double counting pairs (e.g., user-item and item-user)\n",
    "                    interaction = self.pairwise_interaction(emb1, emb2)\n",
    "                    attention_score = self.compute_attention(emb1, emb2)\n",
    "                    interactions.append(interaction * attention_score)  # Weight the interaction by attention score\n",
    "                    attention_scores.append(attention_score)  # Store the attention scores\n",
    "        \n",
    "        # Combine all interactions into a single tensor\n",
    "        interactions = torch.stack(interactions, dim=1)  # Shape: [batch_size, num_interactions]\n",
    "        attention_scores = torch.stack(attention_scores, dim=1)  # Shape: [batch_size, num_interactions]\n",
    "        \n",
    "        # Sum over all interactions with their respective attention scores\n",
    "        weighted_interactions = torch.sum(interactions * attention_scores, dim=1)\n",
    "        \n",
    "        # Pass through output layer to get the final prediction\n",
    "        y = self.output_layer(weighted_interactions)\n",
    "        \n",
    "        output = x + y\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80b8a23b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:26.833647900Z",
     "start_time": "2024-12-06T04:34:26.817598200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:27.961427Z",
     "iopub.status.busy": "2024-12-06T14:06:27.961119Z",
     "iopub.status.idle": "2024-12-06T14:06:27.965258Z",
     "shell.execute_reply": "2024-12-06T14:06:27.964584Z"
    },
    "papermill": {
     "duration": 0.009685,
     "end_time": "2024-12-06T14:06:27.967002",
     "exception": false,
     "start_time": "2024-12-06T14:06:27.957317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input dimension\n",
    "input_dim = (CONFIG['user_emb_size'] + \n",
    "             CONFIG['item_emb_size'] + \n",
    "             CONFIG['source_emb_size'] + \n",
    "             CONFIG['age_emb_size'] +\n",
    "             CONFIG['duration_emb_size'] + \n",
    "             CONFIG['gender_emb_size'] + \n",
    "             CONFIG['timespent_emb_size'] +\n",
    "             32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e891c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T04:34:29.432036Z",
     "start_time": "2024-12-06T04:34:26.838648100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:27.973622Z",
     "iopub.status.busy": "2024-12-06T14:06:27.973381Z",
     "iopub.status.idle": "2024-12-06T14:06:30.884378Z",
     "shell.execute_reply": "2024-12-06T14:06:30.883450Z"
    },
    "papermill": {
     "duration": 2.916933,
     "end_time": "2024-12-06T14:06:30.886715",
     "exception": false,
     "start_time": "2024-12-06T14:06:27.969782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model creation\n",
    "model = AFMModel(input_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fc21a18",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-06T04:34:34.774996700Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T14:06:30.894801Z",
     "iopub.status.busy": "2024-12-06T14:06:30.894380Z",
     "iopub.status.idle": "2024-12-06T15:08:43.270646Z",
     "shell.execute_reply": "2024-12-06T15:08:43.269703Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 3732.383323,
     "end_time": "2024-12-06T15:08:43.273420",
     "exception": false,
     "start_time": "2024-12-06T14:06:30.890097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 8891/8891 [20:46<00:00,  7.13batch/s, mean_loss=0.132350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]: Train Loss: 0.1324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 8891/8891 [20:45<00:00,  7.14batch/s, mean_loss=0.123701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3]: Train Loss: 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 8891/8891 [20:40<00:00,  7.17batch/s, mean_loss=0.122130]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3]: Train Loss: 0.1221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "num_samples = len(train)\n",
    "num_batches = (num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_samples = len(train)\n",
    "    num_batches = (num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "    \n",
    "    count = 0\n",
    "    with tqdm(range(num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], num_samples)\n",
    "            batch_main = train.iloc[start_idx:end_idx]\n",
    "            batch_user_ids = batch_main['user_id'].values\n",
    "            batch_item_ids = batch_main['item_id'].values\n",
    "\n",
    "            batch_users_meta = users_meta.loc[batch_user_ids]\n",
    "            batch_items_meta = items_meta.loc[batch_item_ids]\n",
    "\n",
    "            batch_user_values = torch.tensor(batch_user_ids, dtype=torch.long, device=device)\n",
    "            batch_item_values = torch.tensor(batch_item_ids, dtype=torch.long, device=device)\n",
    "            batch_timespent_values = torch.tensor(batch_main['timespent'].values, dtype=torch.long, device=device)\n",
    "            \n",
    "            batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "            batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "            batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "            batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "\n",
    "            embeddings = torch.tensor(np.stack(batch_items_meta['embeddings'].values), device=device,\n",
    "                                      dtype=torch.float32)\n",
    "            targets = torch.tensor(batch_main['target'].values, dtype=torch.long, device=device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_user_values, batch_item_values, batch_source_values,\n",
    "                            batch_age_values, batch_duration_values, batch_gender_values, embeddings, batch_timespent_values)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            t.set_postfix(mean_loss=f\"{running_loss / (batch_idx + 1):.6f}\")\n",
    "            count += 1\n",
    "\n",
    "    train_loss = running_loss / count\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{CONFIG['EPOCHS']}]: Train Loss: {train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1935c2ce",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-06T15:08:48.549363Z",
     "iopub.status.busy": "2024-12-06T15:08:48.548956Z",
     "iopub.status.idle": "2024-12-06T15:08:49.732031Z",
     "shell.execute_reply": "2024-12-06T15:08:49.731076Z"
    },
    "is_executing": true,
    "papermill": {
     "duration": 3.83367,
     "end_time": "2024-12-06T15:08:49.733948",
     "exception": false,
     "start_time": "2024-12-06T15:08:45.900278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена в f'/kaggle/working/6.12.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save model_state\n",
    "torch.save({\"model_state_dict\": model.state_dict()}, f\"{CONFIG['models_folder']}{CONFIG['model_path']}\")\n",
    "print(f\"Модель сохранена в f'{CONFIG['models_folder']}{CONFIG['model_path']}'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3773.855185,
   "end_time": "2024-12-06T15:08:58.892108",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-06T14:06:05.036923",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
