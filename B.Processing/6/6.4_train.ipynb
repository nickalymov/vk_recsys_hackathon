{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4c275c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:44.254495Z",
     "iopub.status.busy": "2024-11-26T18:19:44.254160Z",
     "iopub.status.idle": "2024-11-26T18:19:44.261831Z",
     "shell.execute_reply": "2024-11-26T18:19:44.261186Z"
    },
    "papermill": {
     "duration": 0.013941,
     "end_time": "2024-11-26T18:19:44.263350",
     "exception": false,
     "start_time": "2024-11-26T18:19:44.249409",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T18:09:42.123099600Z",
     "start_time": "2024-12-03T18:09:42.106546100Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/data/',\n",
    "    'models_folder' : 'C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/',\n",
    "    \n",
    "    \n",
    "    'train_path' : 'train_interactions.parquet',\n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "    'model_path' : '6.4.pth',\n",
    "    \n",
    "    'user_emb_size' : 256, # 183404\n",
    "    'item_emb_size' : 512, # 337727\n",
    "    'source_emb_size' : 256, # 19613\n",
    "    'age_emb_size' : 256, # 43\n",
    "    'duration_emb_size' : 256, # ~175   \n",
    "    'gender_emb_size' : 256, # 3\n",
    "    'torch_precision' : 40, # number of decimal places for printing numbers\n",
    "        \n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 16384,\n",
    "    'LR' : 0.001,\n",
    "    'EPOCHS' : 3,\n",
    "    'output_dim' : 3\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86d0c997",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:44.269625Z",
     "iopub.status.busy": "2024-11-26T18:19:44.269391Z",
     "iopub.status.idle": "2024-11-26T18:19:47.934358Z",
     "shell.execute_reply": "2024-11-26T18:19:47.933544Z"
    },
    "papermill": {
     "duration": 3.670253,
     "end_time": "2024-11-26T18:19:47.936406",
     "exception": false,
     "start_time": "2024-11-26T18:19:44.266153",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T18:09:44.115331300Z",
     "start_time": "2024-12-03T18:09:42.123099600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7ff0364",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:47.943310Z",
     "iopub.status.busy": "2024-11-26T18:19:47.942911Z",
     "iopub.status.idle": "2024-11-26T18:19:48.004646Z",
     "shell.execute_reply": "2024-11-26T18:19:48.003956Z"
    },
    "papermill": {
     "duration": 0.067107,
     "end_time": "2024-11-26T18:19:48.006392",
     "exception": false,
     "start_time": "2024-11-26T18:19:47.939285",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T18:09:44.798478700Z",
     "start_time": "2024-12-03T18:09:44.115331300Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(42)  \n",
    "torch.cuda.manual_seed_all(42)  \n",
    "np.random.seed(42)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd515fb",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:19:48.013182Z",
     "iopub.status.busy": "2024-11-26T18:19:48.012875Z",
     "iopub.status.idle": "2024-11-26T18:20:05.312581Z",
     "shell.execute_reply": "2024-11-26T18:20:05.311844Z"
    },
    "papermill": {
     "duration": 17.305417,
     "end_time": "2024-11-26T18:20:05.314724",
     "exception": false,
     "start_time": "2024-11-26T18:19:48.009307",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T18:09:51.477509Z",
     "start_time": "2024-12-03T18:09:44.803480500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading data\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['target'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['like', 'dislike'], inplace=True)\n",
    "train['target'] = train['target'].astype('int8')\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['duration'] = items_meta['duration'] - 5\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta['duration'] = items_meta['duration'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta['age'] = users_meta['age'].astype('category')\n",
    "users_meta.set_index('user_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd610fd0",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:05.321504Z",
     "iopub.status.busy": "2024-11-26T18:20:05.321233Z",
     "iopub.status.idle": "2024-11-26T18:20:17.941193Z",
     "shell.execute_reply": "2024-11-26T18:20:17.940430Z"
    },
    "papermill": {
     "duration": 12.625576,
     "end_time": "2024-11-26T18:20:17.943287",
     "exception": false,
     "start_time": "2024-11-26T18:20:05.317711",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T18:10:04.624094300Z",
     "start_time": "2024-12-03T18:09:51.481505300Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = pd.read_csv(f\"{CONFIG['data_folder']}fold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdeea22e",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:19.479846Z",
     "iopub.status.busy": "2024-11-26T18:20:19.479339Z",
     "iopub.status.idle": "2024-11-26T18:20:19.488353Z",
     "shell.execute_reply": "2024-11-26T18:20:19.487532Z"
    },
    "papermill": {
     "duration": 0.014069,
     "end_time": "2024-11-26T18:20:19.489950",
     "exception": false,
     "start_time": "2024-11-26T18:20:19.475881",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T18:10:04.672095100Z",
     "start_time": "2024-12-03T18:10:04.640094700Z"
    }
   },
   "outputs": [],
   "source": [
    "class AFMModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 num_ages=users_meta['age'].nunique(),\n",
    "                 num_durations=items_meta['duration'].nunique(),\n",
    "                 num_genders=users_meta['gender'].nunique(), \n",
    "                 output_dim=CONFIG['output_dim']): \n",
    "        super(AFMModel, self).__init__()\n",
    "        \n",
    "        # Embedding layers for each feature\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "        \n",
    "        # Transformations for embeddings\n",
    "        self.user_emb_transform = nn.Linear(CONFIG['user_emb_size'], 32)\n",
    "        self.item_emb_transform = nn.Linear(CONFIG['item_emb_size'], 32)\n",
    "        self.source_emb_transform = nn.Linear(CONFIG['source_emb_size'], 32)\n",
    "        self.age_emb_transform = nn.Linear(CONFIG['age_emb_size'], 32)\n",
    "        self.duration_emb_transform = nn.Linear(CONFIG['duration_emb_size'], 32)\n",
    "        self.gender_emb_transform = nn.Linear(CONFIG['gender_emb_size'], 32)\n",
    "        \n",
    "        # Attention layer components\n",
    "        self.attention_network = nn.Sequential(\n",
    "            nn.Linear(64, 32),  # 64 comes from the concatenation of two embedding sizes\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(32, output_dim)  # Output layer\n",
    "    \n",
    "    def pairwise_interaction(self, x1, x2):\n",
    "        return x1 * x2  # Element-wise multiplication for feature interaction\n",
    "    \n",
    "    def compute_attention(self, emb1, emb2):\n",
    "        # Concatenate embeddings of the pair of features and pass through attention network\n",
    "        combined_emb = torch.cat([emb1, emb2], dim=-1)  # Concatenate embeddings (dim=-1 is feature dimension)\n",
    "        attention_score = self.attention_network(combined_emb)\n",
    "        attention_score = torch.sigmoid(attention_score)  # Use sigmoid for attention score\n",
    "        return attention_score\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids, embeddings):\n",
    "        # Obtain embeddings for all features\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "        age_emb = self.age_embedding(age_ids)\n",
    "        duration_emb = self.duration_embedding(duration_ids)\n",
    "        gender_emb = self.gender_embedding(gender_ids)\n",
    "        \n",
    "        # Apply linear transformations to embeddings\n",
    "        user_emb = self.user_emb_transform(user_emb)\n",
    "        item_emb = self.item_emb_transform(item_emb)\n",
    "        source_emb = self.source_emb_transform(source_emb)\n",
    "        age_emb = self.age_emb_transform(age_emb)\n",
    "        duration_emb = self.duration_emb_transform(duration_emb)\n",
    "        gender_emb = self.gender_emb_transform(gender_emb)\n",
    "        \n",
    "        # Create dictionary of all embeddings\n",
    "        embeddings_dict = {\n",
    "            'user': user_emb,\n",
    "            'item': item_emb,\n",
    "            'source': source_emb,\n",
    "            'age': age_emb,\n",
    "            'duration': duration_emb,\n",
    "            'gender': gender_emb,\n",
    "            'embeddings': embeddings\n",
    "        }\n",
    "        \n",
    "        interactions = []\n",
    "        attention_scores = []\n",
    "        \n",
    "        # Compute pairwise interactions and their attention scores\n",
    "        for key1, emb1 in embeddings_dict.items():\n",
    "            for key2, emb2 in embeddings_dict.items():\n",
    "                if key1 < key2:  # Avoid double counting pairs (e.g., user-item and item-user)\n",
    "                    interaction = self.pairwise_interaction(emb1, emb2)\n",
    "                    attention_score = self.compute_attention(emb1, emb2)\n",
    "                    interactions.append(interaction * attention_score)  # Weight the interaction by attention score\n",
    "                    attention_scores.append(attention_score)  # Store the attention scores\n",
    "        \n",
    "        # Combine all interactions into a single tensor\n",
    "        interactions = torch.stack(interactions, dim=1)  # Shape: [batch_size, num_interactions]\n",
    "        attention_scores = torch.stack(attention_scores, dim=1)  # Shape: [batch_size, num_interactions]\n",
    "        \n",
    "        # Sum over all interactions with their respective attention scores\n",
    "        weighted_interactions = torch.sum(interactions * attention_scores, dim=1)\n",
    "        \n",
    "        # Pass through output layer to get the final prediction\n",
    "        output = self.output_layer(weighted_interactions)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef82c192",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-26T18:20:19.496467Z",
     "iopub.status.busy": "2024-11-26T18:20:19.496224Z",
     "iopub.status.idle": "2024-11-26T22:43:34.806442Z",
     "shell.execute_reply": "2024-11-26T22:43:34.805520Z"
    },
    "papermill": {
     "duration": 15795.315584,
     "end_time": "2024-11-26T22:43:34.808164",
     "exception": false,
     "start_time": "2024-11-26T18:20:19.492580",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-03T23:16:44.281579600Z",
     "start_time": "2024-12-03T18:10:04.673094600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели для fold 0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6664/6664 [25:24<00:00,  4.37batch/s, mean_loss=0.136424]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6664/6664 [25:35<00:00,  4.34batch/s, mean_loss=0.124044]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6664/6664 [25:48<00:00,  4.30batch/s, mean_loss=0.122094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.1221\n",
      "Модель для fold 0 сохранена в C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/6.4.pth_fold_0\n",
      "VRAM очищена после fold 0.\n",
      "Обучение модели для fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6667/6667 [25:19<00:00,  4.39batch/s, mean_loss=0.136680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6667/6667 [25:25<00:00,  4.37batch/s, mean_loss=0.124328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.1243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6667/6667 [25:23<00:00,  4.38batch/s, mean_loss=0.122358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.1224\n",
      "Модель для fold 1 сохранена в C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/6.4.pth_fold_1\n",
      "VRAM очищена после fold 1.\n",
      "Обучение модели для fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6670/6670 [25:24<00:00,  4.37batch/s, mean_loss=0.135906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6670/6670 [25:24<00:00,  4.38batch/s, mean_loss=0.123825]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6670/6670 [25:23<00:00,  4.38batch/s, mean_loss=0.121946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.1219\n",
      "Модель для fold 2 сохранена в C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/6.4.pth_fold_2\n",
      "VRAM очищена после fold 2.\n",
      "Обучение модели для fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 6673/6673 [25:26<00:00,  4.37batch/s, mean_loss=0.136283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 6673/6673 [25:26<00:00,  4.37batch/s, mean_loss=0.123982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3], Loss: 0.1240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 6673/6673 [25:29<00:00,  4.36batch/s, mean_loss=0.122183]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/3], Loss: 0.1222\n",
      "Модель для fold 3 сохранена в C:/Users/Николай/PycharmProjects/VKRecSys/B.Processing/Модели/6.4.pth_fold_3\n",
      "VRAM очищена после fold 3.\n"
     ]
    }
   ],
   "source": [
    "import gc  # Для сборщика мусора\n",
    "\n",
    "for fold in range(4):\n",
    "    print(f\"Обучение модели для fold {fold}...\")\n",
    "    \n",
    "    # Разделение данных на train и validation\n",
    "    train_data = train[folds['fold'] != fold]\n",
    "    val_data = train[folds['fold'] == fold]\n",
    "    \n",
    "    # Model creation\n",
    "    model = AFMModel().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=CONFIG['LR'])\n",
    "    \n",
    "    # Обучение модели\n",
    "    num_samples = len(train_data)\n",
    "    num_batches = (num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "    \n",
    "    for epoch in range(CONFIG['EPOCHS']):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(range(num_batches), desc=f\"Epoch {epoch+1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "            for batch_idx in t:\n",
    "                start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "                end_idx = min(start_idx + CONFIG['BATCH_SIZE'], num_samples)\n",
    "                batch_main = train.iloc[start_idx:end_idx]\n",
    "                batch_user_ids = batch_main['user_id'].values\n",
    "                batch_item_ids = batch_main['item_id'].values\n",
    "                \n",
    "                batch_users_meta = users_meta.loc[batch_user_ids]\n",
    "                batch_items_meta = items_meta.loc[batch_item_ids]\n",
    "                \n",
    "                batch_user_values = torch.tensor(batch_user_ids, dtype=torch.long, device=device)\n",
    "                batch_item_values = torch.tensor(batch_item_ids, dtype=torch.long, device=device)\n",
    "                \n",
    "                batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "                batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "                batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "                batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "    \n",
    "                embeddings = torch.tensor(np.stack(batch_items_meta['embeddings'].values), device=device, dtype=torch.float32)\n",
    "    \n",
    "                targets = torch.tensor(batch_main['target'].values, dtype=torch.long, device=device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_user_values, batch_item_values, batch_source_values, batch_age_values, batch_duration_values, batch_gender_values, embeddings)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                t.set_postfix(mean_loss=f\"{running_loss / (batch_idx + 1):.6f}\")\n",
    "    \n",
    "        print(f\"Epoch [{epoch+1}/{CONFIG['EPOCHS']}], Loss: {running_loss / num_batches:.4f}\")\n",
    "    \n",
    "    # Сохранение модели для текущего fold\n",
    "    fold_model_path = f\"{CONFIG['models_folder']}{CONFIG['model_path']}_fold_{fold}\"\n",
    "    torch.save({\"model_state_dict\": model.state_dict()}, fold_model_path)\n",
    "    print(f\"Модель для fold {fold} сохранена в {fold_model_path}\")\n",
    "\n",
    "    # Очистка VRAM\n",
    "    del model, optimizer, criterion  # Удаляем объекты модели и оптимизатора\n",
    "    torch.cuda.empty_cache()  # Очищаем видеопамять\n",
    "    gc.collect()  # Сбор мусора в системе\n",
    "    print(f\"VRAM очищена после fold {fold}.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6155403,
     "sourceId": 10000346,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15841.823616,
   "end_time": "2024-11-26T22:43:43.625098",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-26T18:19:41.801482",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
