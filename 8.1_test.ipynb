{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 10000346,
     "sourceType": "datasetVersion",
     "datasetId": 6155403
    }
   ],
   "dockerImageVersionId": 30805,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11564.367599,
   "end_time": "2024-12-11T21:04:42.540998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-11T17:51:58.173399",
   "version": "2.6.0"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "number = '8.1'"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:00.681449Z",
     "iopub.status.busy": "2024-12-11T17:52:00.680691Z",
     "iopub.status.idle": "2024-12-11T17:52:00.688466Z",
     "shell.execute_reply": "2024-12-11T17:52:00.687831Z"
    },
    "papermill": {
     "duration": 0.01399,
     "end_time": "2024-12-11T17:52:00.690098",
     "exception": false,
     "start_time": "2024-12-11T17:52:00.676108",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:41.107282900Z",
     "start_time": "2024-12-22T06:17:41.068284100Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "CONFIG = {\n",
    "    'data_folder' : '/kaggle/input/vkrecsys/',\n",
    "    'val_pred_folder' : '/kaggle/working/',\n",
    "    'test_pred_folder' : '/kaggle/working/',\n",
    "    \n",
    "    'train_path' : 'train_interactions.parquet',\n",
    "    'test_path': 'test_pairs.csv',  \n",
    "    'items_meta_path' : 'items_meta.parquet',\n",
    "    'users_meta_path' : 'users_meta.parquet',\n",
    "    'folds_path' : 'fold.csv',\n",
    "    'val_output_path' : f'{number}_val',\n",
    "    'test_output_path' : f'{number}_test',\n",
    "    \n",
    "    'user_emb_size' : 256, \n",
    "    'item_emb_size' : 256, \n",
    "    'source_emb_size' : 256, \n",
    "    'age_emb_size' : 256, \n",
    "    'duration_emb_size' : 256, \n",
    "    'gender_emb_size' : 256, \n",
    "    \n",
    "    'DEVICE' : 'cuda',\n",
    "    'SEED' : 42,\n",
    "    'BATCH_SIZE' : 16384,\n",
    "    'LR' : 0.001,\n",
    "    'EPOCHS' : 1,\n",
    "    'output_dim' : 3\n",
    "    \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:00.697004Z",
     "iopub.status.busy": "2024-12-11T17:52:00.696504Z",
     "iopub.status.idle": "2024-12-11T17:52:00.701294Z",
     "shell.execute_reply": "2024-12-11T17:52:00.700560Z"
    },
    "papermill": {
     "duration": 0.009767,
     "end_time": "2024-12-11T17:52:00.702837",
     "exception": false,
     "start_time": "2024-12-11T17:52:00.693070",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:41.107282900Z",
     "start_time": "2024-12-22T06:17:41.082282400Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:00.708897Z",
     "iopub.status.busy": "2024-12-11T17:52:00.708657Z",
     "iopub.status.idle": "2024-12-11T17:52:04.564282Z",
     "shell.execute_reply": "2024-12-11T17:52:04.563557Z"
    },
    "papermill": {
     "duration": 3.860843,
     "end_time": "2024-12-11T17:52:04.566316",
     "exception": false,
     "start_time": "2024-12-11T17:52:00.705473",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:42.591358200Z",
     "start_time": "2024-12-22T06:17:41.096283100Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Device, torch decimal places and seed for reproducibility\n",
    "device = torch.device(CONFIG['DEVICE'] if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_printoptions(precision=40) \n",
    "\n",
    "torch.manual_seed(CONFIG['SEED'])  \n",
    "torch.cuda.manual_seed_all(CONFIG['SEED'])  \n",
    "np.random.seed(CONFIG['SEED'])  "
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:04.573510Z",
     "iopub.status.busy": "2024-12-11T17:52:04.573077Z",
     "iopub.status.idle": "2024-12-11T17:52:04.640948Z",
     "shell.execute_reply": "2024-12-11T17:52:04.640230Z"
    },
    "papermill": {
     "duration": 0.073166,
     "end_time": "2024-12-11T17:52:04.642567",
     "exception": false,
     "start_time": "2024-12-11T17:52:04.569401",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:43.221839700Z",
     "start_time": "2024-12-22T06:17:42.594397100Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Load and prepare data\n",
    "train = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['train_path']}\", engine='pyarrow')\n",
    "train['target'] = train['like'] + train['dislike'].replace({1: -1})\n",
    "train.drop(columns=['like', 'dislike'], inplace=True)\n",
    "train['target'] = train['target'].astype('int8')\n",
    "train['target'] = train['target'].replace({-1:0, 0:1, 1:2})\n",
    "\n",
    "test = pd.read_csv(f\"{CONFIG['data_folder']}{CONFIG['test_path']}\")\n",
    "test_to_save = test.copy()\n",
    "\n",
    "items_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['items_meta_path']}\", engine='pyarrow')\n",
    "items_meta['duration'] = items_meta['duration'] - 5\n",
    "items_meta['item_id'] = items_meta['item_id'].astype('category')\n",
    "items_meta['source_id'] = items_meta['source_id'].astype('category')\n",
    "items_meta.set_index('item_id', inplace=True)\n",
    "\n",
    "users_meta = pd.read_parquet(f\"{CONFIG['data_folder']}{CONFIG['users_meta_path']}\", engine='pyarrow')\n",
    "users_meta['age'] = users_meta['age'] - 18\n",
    "users_meta['gender'] = users_meta['gender'].replace({1:0, 2:1})\n",
    "users_meta['user_id'] = users_meta['user_id'].astype('category')\n",
    "users_meta['gender'] = users_meta['gender'].astype('category')\n",
    "users_meta.set_index('user_id', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:04.649076Z",
     "iopub.status.busy": "2024-12-11T17:52:04.648738Z",
     "iopub.status.idle": "2024-12-11T17:52:21.854303Z",
     "shell.execute_reply": "2024-12-11T17:52:21.853335Z"
    },
    "papermill": {
     "duration": 17.211183,
     "end_time": "2024-12-11T17:52:21.856536",
     "exception": false,
     "start_time": "2024-12-11T17:52:04.645353",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:47.982968400Z",
     "start_time": "2024-12-22T06:17:43.227869800Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "user_history = {\n",
    "    user_id: {\n",
    "        \"embeddings_like\": [],\n",
    "        \"embeddings_dislike\": [],\n",
    "        \"embeddings_ignore\": [],\n",
    "    }\n",
    "    for user_id in range(train['user_id'].nunique())\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:48.890705800Z",
     "start_time": "2024-12-22T06:17:47.988627300Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 num_users=users_meta.index.nunique(), \n",
    "                 num_items=items_meta.index.nunique(), \n",
    "                 num_sources=items_meta['source_id'].nunique(),\n",
    "                 num_ages=users_meta['age'].nunique(),\n",
    "                 num_durations=items_meta['duration'].nunique(),\n",
    "                 num_genders=users_meta['gender'].nunique(), \n",
    "                 output_dim=CONFIG['output_dim']): \n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "        \n",
    "        self.user_embedding_dcn = nn.Embedding(num_users, CONFIG['user_emb_size'])\n",
    "        self.item_embedding_dcn = nn.Embedding(num_items, CONFIG['item_emb_size'])\n",
    "        self.source_embedding_dcn = nn.Embedding(num_sources, CONFIG['source_emb_size'])\n",
    "        self.age_embedding_dcn = nn.Embedding(num_ages, CONFIG['age_emb_size'])\n",
    "        self.duration_embedding_dcn = nn.Embedding(num_durations, CONFIG['duration_emb_size'])\n",
    "        self.gender_embedding_dcn = nn.Embedding(num_genders, CONFIG['gender_emb_size'])\n",
    "         \n",
    "        self.fc1 = nn.Linear(input_dim, input_dim)\n",
    "        self.fc2 = nn.Linear(input_dim, input_dim)\n",
    "        self.fc3 = nn.Linear(input_dim, input_dim)\n",
    "        self.fc4 = nn.Linear(input_dim + input_dim, output_dim)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.num_cross_layers = 3\n",
    "        \n",
    "        self.cross_weights = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim, input_dim)) for _ in range(self.num_cross_layers)]\n",
    "        )\n",
    "        self.cross_biases = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(input_dim)) for _ in range(self.num_cross_layers)]\n",
    "        )\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        # Xavier для линейных слоев\n",
    "        for layer in [self.fc1, self.fc2, self.fc3, self.fc4]:\n",
    "            init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                init.zeros_(layer.bias)\n",
    "        \n",
    "        # Xavier для эмбеддингов\n",
    "        for embedding in [self.user_embedding, self.item_embedding, self.source_embedding, \n",
    "                          self.age_embedding, self.duration_embedding, self.gender_embedding,\n",
    "                          self.user_embedding_dcn, self.item_embedding_dcn, self.source_embedding_dcn, \n",
    "                          self.age_embedding_dcn, self.duration_embedding_dcn, self.gender_embedding_dcn]:\n",
    "            init.xavier_uniform_(embedding.weight)\n",
    "        \n",
    "        # Xavier для DCNv2 слоев\n",
    "        for weight in self.cross_weights:\n",
    "            init.xavier_uniform_(weight)\n",
    "        for bias in self.cross_biases:\n",
    "            init.zeros_(bias)\n",
    "\n",
    "    def DCNv2_forward(self, x):\n",
    "        # Инициализируем x0\n",
    "        x0 = x\n",
    "        for i in range(self.num_cross_layers):\n",
    "            x = x0 * (x @ self.cross_weights[i]) + self.cross_biases[i] + x\n",
    "        return x\n",
    "    \n",
    "    def forward(self, user_ids, item_ids, source_ids, age_ids, duration_ids, gender_ids, embeddings, prev_embeddings):\n",
    "\n",
    "        user_emb = self.user_embedding(user_ids)\n",
    "        item_emb = self.item_embedding(item_ids)\n",
    "        source_emb = self.source_embedding(source_ids)\n",
    "        age_emb = self.age_embedding(age_ids)\n",
    "        duration_emb = self.duration_embedding(duration_ids)\n",
    "        gender_emb = self.gender_embedding(gender_ids)\n",
    "        \n",
    "        user_emb_dcn = self.user_embedding_dcn(user_ids)\n",
    "        item_emb_dcn = self.item_embedding_dcn(item_ids)\n",
    "        source_emb_dcn = self.source_embedding_dcn(source_ids)\n",
    "        age_emb_dcn = self.age_embedding_dcn(age_ids)\n",
    "        duration_emb_dcn = self.duration_embedding_dcn(duration_ids)\n",
    "        gender_emb_dcn = self.gender_embedding_dcn(gender_ids)\n",
    "        \n",
    "        x = torch.cat((user_emb, item_emb, source_emb, age_emb, duration_emb, gender_emb, embeddings, prev_embeddings), dim=1)\n",
    "        x_dcn = torch.cat((user_emb_dcn, item_emb_dcn, source_emb_dcn, age_emb_dcn, duration_emb_dcn, gender_emb_dcn, embeddings, prev_embeddings), dim=1)\n",
    "        \n",
    "        x_dcn = self.DCNv2_forward(x_dcn)\n",
    "        \n",
    "        x = self.relu(self.fc1(x))\n",
    "        \n",
    "        \n",
    "        x_combined = torch.cat((x, x_dcn), dim=1)\n",
    "        \n",
    "        x_out = self.fc4(x_combined)\n",
    "        \n",
    "        return x_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:48.934251100Z",
     "start_time": "2024-12-22T06:17:48.912251700Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Input dimension\n",
    "input_dim = (CONFIG['user_emb_size'] + \n",
    "             CONFIG['item_emb_size'] + \n",
    "             CONFIG['source_emb_size'] + \n",
    "             CONFIG['age_emb_size'] +\n",
    "             CONFIG['duration_emb_size'] + \n",
    "             CONFIG['gender_emb_size'] + \n",
    "             32 + 96)"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:21.902871Z",
     "iopub.status.busy": "2024-12-11T17:52:21.902323Z",
     "iopub.status.idle": "2024-12-11T17:52:21.906328Z",
     "shell.execute_reply": "2024-12-11T17:52:21.905647Z"
    },
    "papermill": {
     "duration": 0.009314,
     "end_time": "2024-12-11T17:52:21.907857",
     "exception": false,
     "start_time": "2024-12-11T17:52:21.898543",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:48.950251900Z",
     "start_time": "2024-12-22T06:17:48.935251800Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Model, criterion and optimizer\n",
    "model = Model(input_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=CONFIG['LR'])"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:21.914496Z",
     "iopub.status.busy": "2024-12-11T17:52:21.913962Z",
     "iopub.status.idle": "2024-12-11T17:52:25.717689Z",
     "shell.execute_reply": "2024-12-11T17:52:25.717034Z"
    },
    "papermill": {
     "duration": 3.8092,
     "end_time": "2024-12-11T17:52:25.719757",
     "exception": false,
     "start_time": "2024-12-11T17:52:21.910557",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:52.324398800Z",
     "start_time": "2024-12-22T06:17:48.950251900Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "train_targets = train['target'].tolist()\n",
    "train_items = train['item_id'].tolist()\n",
    "test_items = test['item_id'].tolist()\n",
    "items_embs = items_meta['embeddings'].to_dict()\n",
    "train_users = train['user_id'].tolist()\n",
    "test_users = test['user_id'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:52.492352900Z",
     "start_time": "2024-12-22T06:17:52.349451400Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def get_user_embedding_with_targets(user_id, user_history, item_emb):\n",
    "    \n",
    "    like_emb = np.full(32, 0)\n",
    "    dislike_emb = np.full(32, 0)\n",
    "    ignore_emb = np.full(32, 0)\n",
    "\n",
    "    liked_embs = user_history[user_id]['embeddings_like']\n",
    "    disliked_embs = user_history[user_id]['embeddings_dislike']\n",
    "    ignore_embs = user_history[user_id]['embeddings_dislike']\n",
    "\n",
    "    if liked_embs:\n",
    "        like_emb = min(liked_embs, key=lambda emb: cosine(emb, item_emb))\n",
    "    \n",
    "    if disliked_embs:\n",
    "        dislike_emb = min(disliked_embs, key=lambda emb: cosine(emb, item_emb))\n",
    "\n",
    "    if ignore_embs:\n",
    "        ignore_emb = min(ignore_embs, key=lambda emb: cosine(emb, item_emb))\n",
    "\n",
    "    return np.concatenate((like_emb, dislike_emb, ignore_emb))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:52.610093400Z",
     "start_time": "2024-12-22T06:17:52.486355500Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def update_user_history(user_id, user_history, item_emb, target):\n",
    "    \n",
    "    if target == 2:\n",
    "        user_history[user_id]['embeddings_like'].append(item_emb)\n",
    "    \n",
    "    elif target == 1:\n",
    "        user_history[user_id]['embeddings_ignore'].append(item_emb)\n",
    "        \n",
    "    else:\n",
    "        user_history[user_id]['embeddings_dislike'].append(item_emb)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-22T06:17:52.626106900Z",
     "start_time": "2024-12-22T06:17:52.611076700Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train_num_samples = len(train)\n",
    "train_num_batches = (train_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "test_num_samples = len(test)\n",
    "test_num_batches = (test_num_samples + CONFIG['BATCH_SIZE'] - 1) // CONFIG['BATCH_SIZE']\n",
    "\n",
    "for epoch in range(CONFIG['EPOCHS']):\n",
    "##################################################################TRAIN##################################################################\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "\n",
    "    with tqdm(range(train_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as t:\n",
    "        for batch_idx in t:\n",
    "            start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "            end_idx = min(start_idx + CONFIG['BATCH_SIZE'], train_num_samples)\n",
    "            \n",
    "            batch_main = train.iloc[start_idx:end_idx]\n",
    "            \n",
    "            batch_user_values = batch_main['user_id'].values\n",
    "            batch_item_values = batch_main['item_id'].values\n",
    "            \n",
    "            batch_users_meta = users_meta.loc[batch_user_values]\n",
    "            batch_items_meta = items_meta.loc[batch_item_values]\n",
    "            \n",
    "            targets = batch_main['target'].values\n",
    "            embeddings = np.stack(batch_items_meta['embeddings'].values)\n",
    "            \n",
    "            batch_embeddings = []\n",
    "            \n",
    "            for i in range(start_idx, end_idx):\n",
    "                user_id = train_users[i]\n",
    "                target = train_targets[i]\n",
    "                item = train_items[i]\n",
    "                emb = items_embs[item]\n",
    "                user_emb = get_user_embedding_with_targets(user_id, user_history, emb)\n",
    "                update_user_history(user_id, user_history, emb, target)\n",
    "                batch_embeddings.append(user_emb)\n",
    "            \n",
    "            targets = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "            embeddings = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "\n",
    "            batch_user_values = torch.tensor(batch_user_values, dtype=torch.long, device=device)\n",
    "            batch_item_values = torch.tensor(batch_item_values, dtype=torch.long, device=device)\n",
    "\n",
    "            batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "            batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "            batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "            batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "\n",
    "                        \n",
    "            batch_embeddings = torch.tensor(np.array(batch_embeddings), dtype=torch.float32, device=device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(batch_user_values, \n",
    "                            batch_item_values, \n",
    "                            batch_source_values, \n",
    "                            batch_age_values, \n",
    "                            batch_duration_values, \n",
    "                            batch_gender_values, \n",
    "                            embeddings,\n",
    "                            batch_embeddings)\n",
    "            \n",
    "            batch_loss = criterion(outputs, targets)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_running_loss += batch_loss.item()\n",
    "            t.set_postfix(train_mean_loss=f\"{train_running_loss / (batch_idx + 1):.6f}\")\n",
    "        \n",
    "##################################################################EVAL##################################################################\n",
    "    model.eval()\n",
    "    \n",
    "    outputs_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(range(test_num_batches), desc=f\"Epoch {epoch + 1}/{CONFIG['EPOCHS']}\", unit=\"batch\") as v:\n",
    "            for batch_idx in v:\n",
    "                start_idx = batch_idx * CONFIG['BATCH_SIZE']\n",
    "                end_idx = min(start_idx + CONFIG['BATCH_SIZE'], test_num_samples)\n",
    "                \n",
    "                batch_main = test.iloc[start_idx:end_idx]\n",
    "                \n",
    "                batch_user_values = batch_main['user_id'].values\n",
    "                batch_item_values = batch_main['item_id'].values\n",
    "    \n",
    "                batch_users_meta = users_meta.loc[batch_user_values]\n",
    "                batch_items_meta = items_meta.loc[batch_item_values]\n",
    "                \n",
    "                embeddings = np.stack(batch_items_meta['embeddings'].values)\n",
    "                \n",
    "                batch_embeddings = []\n",
    "                \n",
    "                for i in range(start_idx, end_idx):\n",
    "                    user_id = test_users[i]\n",
    "                    item = test_items[i]\n",
    "                    emb = items_embs[item]\n",
    "                    user_emb = get_user_embedding_with_targets(user_id, user_history, emb)\n",
    "                    batch_embeddings.append(user_emb)\n",
    "                    \n",
    "                embeddings = torch.tensor(embeddings, device=device, dtype=torch.float32)\n",
    "\n",
    "                batch_user_values = torch.tensor(batch_user_values, dtype=torch.long, device=device)\n",
    "                batch_item_values = torch.tensor(batch_item_values, dtype=torch.long, device=device)\n",
    "    \n",
    "                batch_gender_values = torch.tensor(batch_users_meta['gender'].values, dtype=torch.long, device=device)\n",
    "                batch_age_values = torch.tensor(batch_users_meta['age'].values, dtype=torch.long, device=device)\n",
    "                batch_source_values = torch.tensor(batch_items_meta['source_id'].values, dtype=torch.long, device=device)\n",
    "                batch_duration_values = torch.tensor(batch_items_meta['duration'].values, dtype=torch.long, device=device)\n",
    "         \n",
    "                batch_embeddings = torch.tensor(np.array(batch_embeddings), dtype=torch.float32, device=device)\n",
    "                \n",
    "                outputs = model(batch_user_values, \n",
    "                                batch_item_values, \n",
    "                                batch_source_values, \n",
    "                                batch_age_values, \n",
    "                                batch_duration_values, \n",
    "                                batch_gender_values, \n",
    "                                embeddings,\n",
    "                                batch_embeddings)\n",
    "                \n",
    "                probabilities = F.softmax(outputs, dim=1)\n",
    "                class_weights = torch.tensor([0, 1, 2], device=probabilities.device, dtype=probabilities.dtype)\n",
    "                weighted_predictions = torch.sum(probabilities * class_weights, dim=1).cpu().numpy()\n",
    "        \n",
    "                outputs_list.extend(weighted_predictions)\n",
    "\n",
    "##################################################################SAVE##################################################################\n",
    "    df_outputs = pd.DataFrame(outputs_list, columns=['predict'])\n",
    "    test_to_save['predict'] = df_outputs['predict']\n",
    "    output_path = f\"{CONFIG['test_pred_folder']}{CONFIG['test_output_path']}_e{epoch}.csv\"\n",
    "    test_to_save.to_csv(output_path, index=False)\n",
    "\n",
    "    train_loss = train_running_loss / train_num_batches\n",
    "\n",
    "    print('Outputs saved at', output_path)\n",
    "    print(f\"Epoch [{epoch + 1}/{CONFIG['EPOCHS']}]: Train Loss: {train_loss:.6f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-12-11T17:52:25.726872Z",
     "iopub.status.busy": "2024-12-11T17:52:25.726463Z",
     "iopub.status.idle": "2024-12-11T21:04:35.927281Z",
     "shell.execute_reply": "2024-12-11T21:04:35.926103Z"
    },
    "papermill": {
     "duration": 11530.206546,
     "end_time": "2024-12-11T21:04:35.929216",
     "exception": false,
     "start_time": "2024-12-11T17:52:25.722670",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-12-22T06:18:27.933598200Z",
     "start_time": "2024-12-22T06:17:52.635082100Z"
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
